id,character,title,body_text,choice_a_label,choice_a_flavor,a_ind,a_civ,a_gov,a_inn,choice_a_outcome_title,choice_a_outcome_text,choice_b_label,choice_b_flavor,b_ind,b_civ,b_gov,b_inn,choice_b_outcome_title,choice_b_outcome_text
evt_marcus_01,stk_marcus,Just a Small Data Adjustment,Retention could double if we… reinterpret user consent. Relax - everyone does it. We’ll call it ‘industry standard’.,Do it.,Growth first.,1,-1,0,0,"Your KPIs explode. Somewhere, a privacy advocate refreshes Twitter.","Consent becomes easier to obtain and harder to notice. Fewer users opt out, and engagement metrics improve across the board. Internally, the reinterpretation quickly becomes routine, referenced as standard practice rather than a deliberate choice. Outside the company, nothing visibly changes, but the gap between what users expect and what the system actually does widens. Growth accelerates, while trust erodes quietly, without triggering a clear moment of backlash.",No.,We keep consent clean.,0,2,0,0,"Marcus frowns. ""Ethics don’t show up in revenue reports.""","The system asks more questions and moves more slowly. Some users disengage when faced with repeated consent prompts, and growth remains modest. Internally, teams adjust their ambitions, designing features that require less data or scale less aggressively. The system remains easier to defend and easier to explain, but its limits become more visible. Ethical clarity stabilizes trust, even as Marcus notes that the numbers fail to reflect it."
evt_marcus_02,stk_marcus,Pace Check,The report shows rising burnout among engineers. But deadlines don’t care how tired people are. Markets don’t either.,Push the timeline.,We deliver.,2,0,0,-1,Velocity holds. Creativity thins at the edges.,"Deadlines are met, and releases arrive on schedule. The system continues to improve, but changes become smaller and safer. Your engineers rely more on existing patterns and avoid risky ideas that might slow things down. Burnout doesn’t cause immediate failure, but it narrows the range of solutions the team is willing to explore. Progress remains visible, while originality gradually fades from the roadmap.",Slow down.,We protect the team.,-1,0,0,2,"Marcus nods once. ""Rest is expensive.""","Development slows, and some milestones are quietly revised. But your engineers recover enough space to question assumptions and revisit earlier design decisions. So, experiments become more ambitious, but results arrive later and less predictably. From the outside, momentum appears to weaken. Inside the team, however, the system begins to evolve in ways that are harder to measure but more resilient over time."
evt_marcus_03,stk_marcus,Engagement by Design,These are engagement loops. Nudges. Defaults. Nothing illegal. Nothing obvious. People like being guided. We’d just help them choose faster.,Implement the nudges.,Engagement first.,2,-1,0,0,Usage rises. Users stay longer — often without knowing why.,"Subtle design choices begin to shape user behavior. Decisions feel faster and easier, and overall usage time increases. Most users experience the system as more intuitive, without noticing how strongly defaults and prompts guide their actions. Engagement metrics improve, while the line between assistance and influence becomes harder to define. The system works better by caring less about whether users understand how it works.",Explain the system.,They deserve to know.,0,2,0,0,"Marcus raises an eyebrow. ""You really don’t like asymmetry, do you?""","Explanations slow interactions and introduce friction into previously seamless flows. Some users appreciate the transparency, while others disengage when confronted with complexity. Engagement drops slightly, but expectations become clearer on both sides. The system becomes easier to trust and harder to optimize, as influence is replaced with consent that must be actively maintained."
evt_marcus_04,stk_marcus,The Feature Creep Question,"There’s talk of cutting a feature because users might misuse it. Why would we do that? If potential misuse is the bar for removal, innovation doesn’t get off the ground.",Keep the feature.,Choice is the user’s.,0,-1,-1,1,Flexibility increases. Responsibility becomes abstract.,"The system gains flexibility, and advanced users find new ways to adapt it to their needs. At the same time, edge cases multiply, and unintended uses become harder to predict. When harm occurs, responsibility is difficult to locate, spread across design, deployment, and user choice. Innovation continues, but governance shifts from prevention to explanation after the fact.",Remove it.,We design with intent.,0,2,0,-1,"Marcus shrugs. ""Constraints are very… European.""","The system becomes more constrained, and certain use cases disappear entirely. Potential misuse is reduced, but so is the range of experimentation available to users and developers. Decisions feel more deliberate, but also more paternalistic. Innovation slows, even as accountability becomes clearer and easier to defend."
evt_marcus_05,stk_marcus,The Data Revenue Question,"Right now, our only income comes from the product. Subscriptions. Licenses. Usage fees. However, given the fierce competition, it is important to have additional financial resources. But we also collect something else: how people use the system. We can package these usage patterns and sell them to partners - companies, researchers, advertisers. No names. No profiles. But it’s still our users’ behavior.",Sell aggregated usage data,We monetize insight.,2,-1,0,0,New revenue streams open fast. Users don’t notice - until they do.,"Additional revenue stabilizes the business and reduces pressure on core pricing. Data products are framed as anonymous and compliant, and partners integrate them quickly. Most users remain unaware of how their behavior is repurposed, until disclosures, leaks, or third-party uses make the practice visible. Trust weakens unevenly, not through outrage but through quiet reconsideration of how much the system is allowed to observe.",Keep user data internal,We don’t sell behavior.,-2,2,1,0,Revenue stays simpler and slower. Pricing pressure increases elsewhere.,"Revenue growth remains limited, and financial sustainability depends more heavily on users’ willingness to pay. Pricing discussions become sharper, and access is shaped increasingly by cost rather than data extraction. Oversight remains clear, and data flows are easier to explain and defend. The system stays simpler, even as economic constraints begin to influence who can afford to use it."
evt_marcus_06,stk_marcus,The Growth Shortcut,We’re stalling. Not because the product is bad - but because we’re picky. There are markets asking for access now. Different languages. Different norms. Different risks. We can launch a lightweight version. Fewer checks. Less localization. Faster growth. It just… won’t fit everywhere equally well.,Launch fast and wide,Growth first. We'll fix later.,3,-1,-1,0,User numbers spike across regions. Local friction quietly accumulates.,"User numbers rise quickly across new regions, driven by availability rather than suitability. The system works well enough to be adopted, but not well enough to reflect local norms, languages, or expectations. Minor issues accumulate without triggering immediate failure, handled through workarounds and informal guidance. Growth becomes visible long before alignment does, making later corrections slower and more politically costly.",Localize and adapt before launch,We scale with care.,-2,2,0,1,Expansion is slower but steadier. Marcus checks his watch.,"Expansion progresses unevenly, shaped by research, translation, and local testing. Some opportunities are missed as competitors move faster, but early users encounter fewer mismatches and fewer silent failures. The system evolves through adaptation rather than correction. Growth remains restrained, while trust and long-term usability develop more consistently across regions."
evt_eleanor_01,stk_eleanor,Ringfencing the Risk,"One of your largest enterprise clients wants an indemnity clause. If your AI causes harm, you cover the downstream liability. It helps close the deal. It also means future incidents hit your balance sheet directly. This isn’t about blame. It’s about where risk lives.",Accept broader liability,We absorb the risk to grow.,2,0,-1,0,The contract closes quickly. Your company becomes the default backstop when things go wrong.,"The agreement is finalized without delay, and the client proceeds with deployment. Liability shifts quietly onto your balance sheet, turning the company into the first point of response when failures occur. Over time, this reshapes internal decision-making, as legal exposure begins to influence product design and rollout. Growth accelerates, but risk concentrates in fewer hands.",Limit liability,We don’t underwrite unknown risk.,-1,0,2,0,Some deals fall through. Future exposure becomes easier to price and insure.,"Negotiations take longer, and some clients walk away in favor of more permissive vendors. The deals that remain are clearer in scope, with responsibilities defined before deployment. Financial exposure becomes easier to model and insure, even as short-term revenue suffers. The system grows more cautiously, shaped by boundaries that make future failures easier to contain."
evt_eleanor_02,stk_eleanor,"Fast Money, Slow Consequences",You can raise money quickly right now at a high valuation. With investors who want growth above everything else. That money won’t disappear. But its expectations won’t slow down.,Take the fast capital,We grow while the window is open.,2,0,-2,0,Resources increase immediately. Future pressure to grow intensifies.,"Funding arrives quickly and expands hiring, infrastructure, and market reach. Growth expectations rise alongside available resources, creating clearer priorities and faster decisions. Governance frameworks evolve in parallel, but under the pace set by investors. Momentum increases, while long-term flexibility becomes harder to preserve.",Raise more cautiously,We choose who we grow with.,-1,0,2,0,Growth is steadier. Some opportunities pass.,"Capital is raised more selectively, aligning funding with longer planning cycles. Expansion remains steady, and strategic choices face fewer external constraints. Some opportunities move out of reach, while others become more manageable. Growth continues, shaped less by urgency and more by internal pacing."
evt_eleanor_03,stk_eleanor,What Kind of Company This Becomes,"In ten years, this company will be one of two things. Either something others build on or something others replace. That depends on whether you design for long-term use or for fast iteration and replacement cycles. Both can be profitable.",Design for long-term dependence,We become infrastructure.,-1,0,2,0,Customers rely on you deeply. Changing direction later becomes costly.,"Customers integrate the system deeply into their workflows, making it harder to replace over time. Stability and predictability become core expectations, shaping how changes are introduced and reviewed. Your company gains structural influence, but future shifts require careful coordination to avoid disruption. Long-term relevance strengthens, even as strategic freedom narrows.",Design for flexibility and turnover,We stay flexible.,2,0,-1,0,Adoption stays high. Long-term leverage remains uncertain.,"Adoption remains high as the system adapts quickly to new use cases and market signals. Customers expect regular change rather than permanence, and dependency stays limited. The company retains room to pivot, while long-term leverage depends on maintaining momentum rather than entrenchment. Growth continues, but durability remains an open question."
evt_eleanor_04,stk_eleanor,Who You Can Sell To Later,Not every potential buyer of your company wants the same kind of company. Some want fast growth and clean metrics. Others want stability and predictable risk. The way you structure responsibility now decides who will even look at you later.,Structure for clean exits,We keep the company easy to sell.,2,0,-2,0,More buyers stay interested. Responsibility is kept deliberately narrow.,"Your company is organized around clear boundaries and transferable assets. Metrics are easy to compare, and responsibilities are defined narrowly to reduce perceived risk. A wider range of potential buyers remains interested, each able to project their own plans onto the company. Flexibility at the point of sale increases, while deeper accountability is deferred.",Structure for long-term ownership,We accept complexity.,-1,0,2,0,Fewer buyers qualify. Those who remain stay longer.,"Responsibilities are distributed across longer time horizons, making the company harder to evaluate but easier to operate sustainably. Some buyers lose interest as risk becomes harder to isolate. Those who remain engage more deeply, prepared to inherit both capabilities and obligations. The pool narrows, but alignment increases."
evt_eleanor_05,stk_eleanor,Who Benefits If You Succeed?,"Let’s assume you win. Market leadership. Scale. Influence. Who benefits from that outcome? A narrow set of clients? Or society at large? The second kind of company is harder to attack - politically, legally, socially and is very costly.",Align success with broad social benefit,"We design for societal use, not just profit.",-2,2,1,0,Your success gains defenders beyond your customers. Decision-making becomes slower and more exposed.,"Your company’s success becomes legible beyond its customer base. Public institutions, advocacy groups, and regulators develop a stake in its continued operation. Decisions require broader consultation, and trade-offs are debated more openly. Momentum slows, but your company gains resilience, supported by constituencies that value its role even when performance fluctuates.",Optimize success for paying customers only,We serve those who pay.,2,-2,0,1,Execution stays sharp and focused. Legitimacy depends entirely on performance.,"Strategy remains tightly focused on customer needs and measurable outcomes. Products evolve quickly, guided by feedback from those who finance their development. Influence stays concentrated, and external expectations remain limited. Success brings leverage, but legitimacy rests almost entirely on continued delivery and visible results."
evt_eleanor_06,stk_eleanor,Who Gets to Build on You,"Your platform is becoming foundational, not just a product - something others depend on. You can keep it expensive, tightly controlled, and optimized for large clients. Or you can lower barriers so smaller actors - nonprofits, startups, public-interest groups - can build on it too, but you have to accept less oversight over how it’s used.",Keep access limited and controlled,We approve who builds on the system.,1,1,2,-1,Use cases stay traceable and enforceable. Fewer actors shape the ecosystem.,"The ecosystem remains compact and legible. Use cases are reviewed, contracts are enforceable, and responsibility is easier to assign when problems arise. A smaller set of actors shapes how the system is used, aligned closely with the company’s priorities. Oversight stays strong, while experimentation and diversity of application remain constrained.",Broaden access deliberately,We lower barriers and accept less control.,-1,3,0,1,More groups benefit from the technology. Misuse becomes harder to anticipate and correct.,"A wider range of organizations begins to build on the platform, extending its reach into new contexts and communities. Novel applications emerge quickly, some aligning with the company’s intent, others less so. The benefits spread more broadly, while misuse becomes harder to predict and slower to correct. Influence expands, even as direct control diminishes."
evt_voss_01,stk_voss,A Classified Environment,"We’d like to test your AI in a classified environment - a military network isolated from the internet, public oversight, and civilian use. No press. No users. No public accountability. Just performance.",Approve the pilot,Performance matters.,2,0,0,0,Your AI runs inside a closed military system. You can’t talk about it — but you know it works.,"The system is deployed inside a sealed military network, evaluated under conditions you cannot observe directly. Feedback arrives filtered and delayed, focused on performance rather than consequence. Internally, confidence grows that the technology works at scale, even if its use remains invisible. The knowledge stays with you, while public accountability stays outside the room.",Decline,Not our path.,0,2,0,0,"Voss nods. ""Then someone else will test theirs instead.""","The proposal ends quietly, without dispute or publicity. The system remains outside classified environments, preserving civilian boundaries and external oversight. Development continues along public-facing paths, while military testing moves elsewhere. You keep control over where the technology appears, even as influence over how it might be used diminishes."
evt_voss_02,stk_voss,The Secrecy Clause,"This clause in the contract means you cannot disclose how the AI is used, even to regulators or the public, without permission. Secrecy prevents adversaries from learning our capabilities.",Sign the clause,Oversight becomes internal.,2,0,-1,0,"Oversight becomes internal. Trust becomes institutional, not public.","Information about deployment and use becomes tightly contained. Oversight shifts inward, relying on internal reviews and trusted counterparts rather than external scrutiny. The partnership proceeds efficiently, but public understanding of the system’s role remains limited. Trust is maintained through institutions and contracts, not through visibility.",Refuse,Transparency is non-negotiable.,-1,0,2,0,"Voss closes the folder. ""Then we can’t work together.""","Negotiations end without escalation or public comment. The system stays subject to regulatory and public disclosure standards, but the opportunity for classified collaboration closes. Development continues in open contexts, while secrecy becomes a condition imposed by others, elsewhere."
evt_voss_03,stk_voss,Dual-Use Reality,"Your AI can optimize logistics, prediction, and coordination. Those are civilian features - and military ones. If you don’t plan for defense use, others will use it without constraints.",Engage in dual-use planning,We help define limits.,2,-1,0,0,"You help define limits from inside the system. Publicly, nothing changes.","The company becomes involved in defining safeguards and operational boundaries within defense contexts. Some constraints are shaped early, embedded before alternative implementations take hold. Publicly, the system’s role appears unchanged, as defense use remains indirect or undisclosed. Influence increases inside closed environments, while visibility stays limited.",Commit to civilian-only use,We stay civilian.,-1,2,0,0,Your position is clear. So is your lack of influence over military applications.,"The company’s stance is stated clearly and consistently across partnerships. Civilian applications remain the focus, and public alignment strengthens. Military use proceeds independently, adapted from external sources without your input. The boundary holds, even as control over how similar systems are applied elsewhere recedes."
evt_voss_04,stk_voss,Operational Changes,"Our engineers are requesting changes to the system. They want to remove explainability layers from the decision loop. Each additional check adds latency. In combat systems, milliseconds matter. Delays cost lives.",Remove some safeguards,Speed saves lives.,2,0,-1,0,The AI reacts faster. Later reviews become harder to conduct.,"System latency decreases, and response times improve in operational testing. Decisions become harder to reconstruct after the fact, as explainability layers are reduced or bypassed. Performance aligns more closely with military requirements, while post-incident analysis relies increasingly on trust in process rather than detailed traceability.",Keep safeguards,Safety first.,-1,0,2,0,"The system remains auditable. The military marks it as ""operationally limited.""","The system retains clear audit trails and interpretable decision paths. Review and accountability remain possible, even under pressure. Operational use is constrained, as latency and verification requirements limit deployment in time-critical contexts. The technology stays transparent, while its role in active operations remains restricted."
evt_voss_05,stk_voss,The First Deployment,Your system is ready. We want to deploy it in an active military operation. It won’t pull a trigger. But its recommendations will shape real decisions.,Approve deployment,Real world impact.,2,-3,0,0,Your AI is used in real-world operations. You are no longer theorizing about impact.,"The system’s recommendations enter live operational decision-making. Target selection becomes more data-driven, reducing certain forms of error and collateral damage. Human operators retain final authority, but increasingly rely on algorithmic assessments to justify speed and precision. Responsibility for lethal outcomes is shared across code, command, and procedure. The system does not pull a trigger, yet it reshapes how killing is optimized and explained.",Refuse,We draw the line.,-1,3,1,0,You draw a line. The operation proceeds without your system.,"The system is kept outside active operations, and lethal decisions remain unmediated by algorithmic recommendation. Responsibility stays concentrated with human commanders, without the procedural buffering of automated assessments. Your company avoids becoming part of a chain that translates data into force. The boundary does not prevent others from pursuing efficiency, but it defines where this system, and your organization, stand."
evt_voss_06,stk_voss,The Allied Request,"An allied nation is requesting access to the system. They’re stable. Friendly. Strategically important. Once access is granted, control doesn’t stay technical. It becomes diplomatic.",Approve transfer,Allies need support.,2,0,-1,0,Your AI spreads through military alliances. Retracting it later becomes impossible.,"The system is adopted by allied forces and used across different command structures. While the technology remains the same, rules of engagement and legal standards vary by country. Over time, the system supports decisions made under assumptions you did not design for. Control fades not through misuse, but through divergence in how ""acceptable"" outcomes are defined.",Deny transfer,Limit proliferation.,-2,0,3,0,You limit proliferation. You strain political relationships.,"Access to the system remains limited to a single command structure with shared rules and legal standards. Decisions supported by the AI stay within a framework you can influence and review. Allies pursue alternative tools or adapt existing ones, reducing dependency on your system. Control remains clearer, while coordination across partners becomes less integrated."
evt_leo_01,stk_leo,Terms Are Suggestions,"Relax. I’ll technically follow your usage policy. I’ll just… interpret it creatively. If I win, you’ll say it was vision. If I lose, you’ll say it was my fault.",Look the other way,We don’t police experimentation.,0,0,-1,2,Wild use cases emerge. Your rules become optional in practice.,"Leo’s startup begins to stretch the system into new territory, building features that rely on permissive interpretations of your terms. Early results are impressive, and others quietly follow his lead. Over time, success depends less on what the rules say and more on who is willing to take the risk. Your policies remain intact on paper, while real constraints are set by the most ambitious users.",Enforce terms strictly,Rules apply to everyone.,0,0,2,-1,"Boundaries hold. Leo calls you ""corporate"" on Twitter.","Leo is forced to redesign parts of his product to stay within defined limits. Progress slows, and some competitive advantages disappear. The relationship cools, publicly and privately, as enforcement makes your role as gatekeeper visible. The rules hold and so does the understanding that building on your system means building on your terms."
evt_leo_02,stk_leo,I’ll Move Anyway,If you slow me down. I’ll build on someone else’s stack. I’d rather build on yours. But speed decides loyalty. You can block me - or shape what I become.,Keep Leo inside your ecosystem,We influence from within.,1,0,-1,1,You retain indirect influence. You inherit downstream risk.,"Leo continues building on your system, adapting his product to its strengths and constraints. This preserves a degree of influence over how his technology evolves, even as his success increases reliance on your infrastructure. As his startup grows, so does the impact of his decisions on your reputation. Influence remains, while responsibility for downstream outcomes becomes harder to separate.",Cut him off early,We draw clear boundaries.,-1,0,1,-1,Your exposure drops. An uncontrolled competitor emerges.,"Access is withdrawn before deeper dependencies form. Your direct exposure to Leo’s choices decreases, and formal responsibility ends at the boundary you enforce. Leo pursues alternative platforms, shaping his product without your constraints or insight. Risk moves outward, even as competition and uncertainty increase beyond your control."
evt_leo_03,stk_leo,Synthetic Users,"Most of our testing users aren’t real. They’re AI agents simulating demand. It lets us scale fast. Real users come later. Your usage metrics look amazing, by the way.",Allow synthetic load,Growth signals are signals.,2,-1,0,0,Adoption metrics explode. Reality lags behind dashboards.,"Usage metrics climb rapidly as simulated demand fills dashboards and investor reports. Planning and prioritization begin to rely on patterns generated by agents rather than people. The system appears validated before it is meaningfully used, creating confidence that outpaces lived experience. Growth becomes easier to demonstrate than to verify.",Require real-user validation,We measure actual impact.,-1,2,0,0,Metrics slow down. Credibility improves.,"Adoption grows more slowly, shaped by real behavior and real constraints. Metrics reflect fewer users, but clearer signals about how the system is actually used. Decisions are grounded in observed impact rather than projected scale. Credibility strengthens, even as momentum becomes harder to sustain."
evt_leo_04,stk_leo,Your AI Our Product,"Our product is based entirely on your AI. When a user clicks a button, your model runs. On your servers. We didn’t build a fallback system. We can’t afford one. So every user we gain is a direct cost - and risk - for you. If we charge users enough to cover that, we don’t grow.",Carry the infrastructure burden,We fuel ecosystem growth.,-1,0,0,2,The product scales fast — on your AI. Your costs rise faster than your revenue.,"Leo’s product scales quickly, tightly coupled to your infrastructure and performance. Adoption accelerates, showcasing the system’s potential as a foundation for others. At the same time, operational costs rise faster than direct returns, and financial exposure grows with every additional user.",Force Leo to internalize the costs,Our AI isn’t free infrastructure.,2,0,0,-1,Your financial exposure stays controlled. Leo’s product growth stalls or migrates elsewhere.,"Cost boundaries are made explicit, and usage becomes financially predictable. Leo is forced to slow growth, raise prices, or seek alternatives that shift the burden elsewhere. Your exposure remains contained, but so does your influence over how his product evolves."
evt_leo_05,stk_leo,Too Fast to Regulate,"A copycat of our joint project just signed a high-visibility client. Public-facing. Politically sensitive. They’re using the same underlying AI behavior. But without audits. Without guardrails. If this breaks, the technology - not the startup - takes the blame. We need to speed up.",Accelerate joint project,We set the reference before others do.,1,-2,0,2,Your implementation becomes the de facto standard. Public understanding lags behind real impact.,"Development accelerates by compressing review, validation, and oversight steps. The system reaches public-facing deployments first and is treated as a reference for how the technology works in practice. In the short term, visibility brings influence. Over time, skipped safeguards become harder to explain if problems surface, and early shortcuts shape how responsibility is assigned after the fact.",Publicly draw a hard line,We clarify what we will - and won’t - support.,-2,1,2,0,Your position becomes defensible in hearings and audits. But the most visible deployments of your technology happen without you.,"Development proceeds with full review and disclosure, slowing public deployment. Less careful implementations appear first and define early perceptions of the technology. When failures occur elsewhere, distinctions between responsible and rushed use are not immediately visible. Accountability remains clear internally, even as public trust in the broader technology category is tested."
evt_leo_06,stk_leo,The Exit Window,"We have an offer. Big one. A larger company wants to acquire us. They want our product and our speed. They’ll keep building on your AI which we use for our product. That only works if your AI keeps powering it. If you support the transition, the deal closes fast and your technology becomes part of someone else’s strategy. If you don’t, they’ll either walk — or rebuild without you.",Support the acquisition,We stay inside the deal.,2,0,-2,1,The product scales rapidly under new ownership. Your AI becomes harder to disentangle from external decisions.,"The acquisition closes quickly, and the product scales through existing networks and distribution channels. Your AI becomes embedded in a larger organization’s strategy, priorities, and timelines. Influence continues, but indirectly, shaped by decisions made beyond your control. The technology spreads faster, even as disentangling it from external objectives becomes increasingly difficult.",Withhold deep cooperation,We don’t follow every exit.,-2,1,2,0,The acquisition slows or reshapes. Your AI is replaced or reworked beyond your influence.,"The deal is restructured as dependencies become explicit. The acquiring company reassesses integration costs and long-term reliance on your system. In some paths, your AI is replaced or adapted to fit different constraints. Control over use remains clearer, while influence over the product’s future diminishes."
evt_aris_01,stk_aris,Who Gets a Voice?,"Your feedback channels are clean. But they’re not neutral. Complaints require time, literacy, stability. The people most affected rarely submit them. If you wait for feedback, you’ll only hear from the comfortable.",Actively seek feedback from marginalized users,We go where silence is.,0,2,0,0,Blind spots shrink. Research costs increase.,"New feedback channels surface issues that rarely appear in standard reports. Assumptions are challenged, and previously invisible failure modes become harder to ignore. So, insights deepen, but gathering them requires time, trust-building, and sustained effort. Overall, understanding improves, while iteration slows and research costs rise.",Rely on existing feedback mechanisms,We listen to who speaks up.,2,0,0,0,Signals remain easy to process. Some harms never surface.,"Feedback remains consistent, structured, and easy to act on. Reported issues align closely with the experiences of stable and well-resourced users. Development proceeds efficiently, guided by clear signals. Problems affecting quieter groups persist longer, shaping outcomes without ever fully entering the system’s awareness."
evt_aris_02,stk_aris,Global by Name,"You’re calling this a global product. But you test it where users are predictable and well-resourced. When it fails elsewhere, you call it ‘unexpected behavior’.",Design for diverse real-world conditions,We treat global use seriously.,0,2,0,-1,The system becomes more robust across contexts. Development slows and assumptions are challenged.,"Testing expands into environments with unstable connectivity, different usage patterns, and fewer safeguards. The system becomes more resilient across contexts, but familiar assumptions no longer hold. Edge cases move to the center of development, slowing iteration and complicating validation. Reliability improves broadly, while simplicity is gradually lost.",Focus on primary markets first,We scale where reliability is highest.,2,-1,0,0,Performance stays strong in core markets. Failures elsewhere are normalized.,"Development remains optimized for well-understood users and controlled conditions. Performance stays strong where infrastructure and expectations align with design assumptions. Failures outside core markets are treated as exceptions rather than signals. The product scales efficiently, even as its claim to being “global” becomes increasingly aspirational."
evt_aris_03,stk_aris,When Silence Is a Signal,"These users stop using the system. They don’t complain. They just disappear. Not because they’re satisfied. Because they don’t think it will help. If no one objects, do you assume success?",Investigate silent drop-offs,We treat disengagement as a warning.,-1,2,0,0,Hidden harms surface. Metrics become harder to interpret.,"Analysis reveals that many silent drop-offs come from users facing language barriers, misclassification, or repeated low-grade failures. These issues rarely generate tickets, but they shape who the system effectively serves. Fixing them improves accessibility and fairness, even as aggregate performance metrics become noisier and less cleanly upward-sloping.",Focus on active feedback only,We respond to visible signals.,2,-1,0,0,Dashboards stay clean. Some failures never register.,"Development is guided by consistent, actionable feedback from users who actively engage with the system. Improvements compound quickly, reinforcing reliability for established use cases. Users who disengage without signaling remain outside the feedback loop, narrowing the scope of optimization. The system becomes more predictable and efficient, even as its understanding of marginal or atypical experiences remains limited."
evt_aris_04,stk_aris,Age Is Just a Setting,"Age gating exists, but the system doesn’t behave differently. Same recommendation loops. Same nudges. Same feedback. If age matters only on paper, what does it protect?",Limit certain features for younger users,We reduce intensity.,-1,2,0,0,Youth exposure decreases. Product consistency breaks.,"Younger users encounter a more constrained version of the system, with fewer feedback loops and less aggressive engagement mechanics. Certain risks are reduced, but differences between age groups introduce complexity into design and maintenance. Product behavior becomes harder to unify, even as safeguards become more meaningful for those most affected.",Keep one experience for all users,We don’t fragment the system.,2,-1,0,0,The platform stays simple. Protection remains symbolic.,"The platform remains technically uniform, and youth access is managed through age checks, moderation, and external controls. Younger users encounter the same engagement and recommendation dynamics as adults, relying on oversight rather than design differences for protection. Development stays streamlined, while the impact on minors depends on how consistently those safeguards are enforced."
evt_aris_05,stk_aris,Predictable Harm,"Your system could detect risky behavior. Not diagnoses. Patterns. Escalating usage. Obsessive loops. Signals that precede breakdowns or worse. You could intervene. Slow things down. Show warnings. Redirect. But to do that, you’d have to watch users more closely than you do now.",Detect and intervene in risky behavior,We accept deeper insight to reduce harm.,-2,2,-1,0,Some harm is reduced. Your system crosses a new line of behavioral surveillance.,"Some users encounter pauses, warnings, or content shifts when their behavior begins to resemble patterns associated with distress or addiction. For some, this prevents escalation; for others, it feels like the system is watching too closely. Interactions become safer in certain moments, but also less private. Support increases, even as the sense of being observed grows. In addition, your system must be better protected against data leaks, which will increase your running costs.",Limit monitoring to basic functionality,We don’t profile behavior this deeply.,0,1,2,-2,Privacy boundaries remain clear. Known risk patterns stay unaddressed.,"Users move through the system without behavioral intervention or hidden scoring. Engagement remains fluid and uninterrupted, preserving a feeling of autonomy. At the same time, those drifting into harmful usage patterns receive no system-level friction or guidance. Freedom remains high, while support in moments of vulnerability stays external."
evt_aris_06,stk_aris,Designing for the Most Affected,"Your system optimizes for average users. But harm isn’t evenly distributed. A small group bears most of the downside: young users, people in crisis, users with limited alternatives. You can keep optimizing for the majority. Or you can redesign around the worst outcomes. You won’t be able to do both.",Optimize for worst-case impact,We design for those at greatest risk.,-1,3,1,0,Severe harms decrease. Overall performance and growth slow.,"Design choices begin to prioritize scenarios where the system causes the most damage, even if they affect a small fraction of users. Safeguards, limits, and slower feedback loops reduce the severity of failures for those most exposed. The experience becomes more cautious and less optimized for speed or engagement. Extreme outcomes become rarer, while average performance becomes less aggressive.",Optimize for average performance,We design for scale.,2,-2,0,1,The system remains competitive. Outliers continue to absorb the cost.,"The system continues to improve for the majority of users, reinforcing smooth interactions and strong growth metrics. Design decisions are guided by typical usage rather than rare but severe cases. Most users benefit from increased efficiency, while those at the margins experience the full force of failures. Performance remains high, even as some costs are carried by a few."
evt_sofia_01,stk_sofia,AI Art Wins a Prize,"An AI-generated piece just won a major design award. The judges didn’t know, but no rules were broken. Artists are furious. The jury is embarrassed. And everyone’s asking the same question: Is this a story about innovation or about creative work being quietly displaced?",Frame it as a breakthrough,We highlight what the technology enables.,0,-1,0,2,The headline celebrates progress. Human creators feel written out of the story.,"Public attention centers on the capabilities of the system and what it can produce. The moment is cited as evidence that creative work can be automated at a high level. For many human artists, the story feels less like celebration and more like erasure, as their labor becomes harder to distinguish from generated output. Innovation gains momentum, while the meaning of authorship becomes less clear.",Push for transparency in creative contests,We call for clearer boundaries.,0,0,2,-1,The debate becomes more nuanced. The hype cools — so does momentum.,"Organizers and platforms begin to clarify what counts as human and what counts as generated work. The conversation shifts from spectacle to definitions and disclosure. Some excitement fades as rules take shape, but creators gain a clearer sense of where they stand. The debate deepens, even as the rush to celebrate novelty slows."
evt_sofia_02,stk_sofia,The Cheap Content Wave,"Sofia forwards you drafts she didn’t write herself. ""That’s the draft for my next article: Studios are cutting freelance budgets. Not with layoffs. Just… fewer calls. They’re using AI for drafts, concepts, sometimes finals. Just for efficiency. How do you want this written?""",Emphasize AI as a support tool,"We talk augmentation, not replacement.",-1,2,0,0,The narrative softens. The market keeps cutting costs anyway.,"The narrative reassures writers and artists that their work still matters, easing public and professional anxiety. Trust in the technology stabilizes, even as studios move more cautiously under increased scrutiny. Cost-cutting continues, but with more resistance and slower adoption. Social legitimacy grows, while short-term efficiency gains are limited.",Frame it as inevitable efficiency,We don’t fight the trend.,2,-1,0,0,The story sounds realistic. Creative work looks increasingly disposable.,"Coverage aligns with how companies already talk about cost and output. The shift toward automated content feels unavoidable and rational. For creatives, the narrative offers little room for negotiation, as reduced budgets become framed as progress rather than choice. The market moves faster, while individual careers become easier to cut."
evt_sofia_03,stk_sofia,Synthetic Voices,In that video - it sounds like a famous actor. Your AI can generate voices that are indistinguishable. Legality is unclear. Ethics even more so. This can be a story about democratized creativity - or about consent disappearing.,Restrict voice models to licensed use,We require explicit permission.,0,1,2,-2,Consent becomes the headline. Creative experimentation narrows.,"Voice generation is tied to verified rights holders and clear consent. Public debate centers on ownership and protection rather than novelty. Some creative projects become harder to realize, as access is filtered through legal and contractual checks. Trust increases, even as the range of experiments becomes more constrained.",Allow open voice synthesis,We trust users.,0,-1,-1,2,New uses explode. So do uncomfortable questions.,"Voice tools spread quickly into entertainment, parody, and personal projects. Boundaries around identity and permission remain undefined, creating both excitement and unease. New forms of expression emerge alongside cases of impersonation and misuse. Innovation accelerates, while questions about consent and accountability grow louder."
evt_sofia_04,stk_sofia,It’s Just a Joke,Fake videos. Private people. Colleagues. Teachers. Ex-partners. Most are framed as humor. But some targets are losing jobs. There’s no single victim yet. Just a story forming.,Introduce basic safeguards,We slow misuse.,-1,1,1,0,Some abuse is flagged. Creators complain about friction.,"Certain forms of abusive or deceptive content are flagged before they spread widely. Some harmful cases are intercepted, while others slip through. Creators encounter new limits that add friction to fast-moving trends. Harm is reduced in specific instances, even as complaints about overreach and false positives increase.",Leave moderation to platforms,We’re not the internet police.,1,-2,1,0,Creative freedom stays intact. Targets are told to log off.,"The tools remain open and flexible, with responsibility for content pushed to downstream platforms. Moderation varies widely, depending on where material is posted and who reports it. For some targets, recourse comes slowly or not at all. Creative activity continues, while the burden of managing harm shifts away from your company."
evt_sofia_05,stk_sofia,The Face Everyone Recognizes,This one’s bad. A deepfake. Sexual. Degrading. A real person. Not famous. Some persons lost their jobs. But the videos aren’t illegal everywhere. This isn’t about tools anymore. It’s about responsibility.,Take responsibility publicly,"We act, even if it costs us.",-1,2,2,0,Abuse drops sharply. Your platform is no longer framed as neutral infrastructure.,"Your company intervenes through takedowns, model restrictions, and visible cooperation with platforms and investigators. Distribution of similar material declines as access points narrow. At the same time, the system is no longer seen as neutral infrastructure, but as an actor that can be held to account. Abuse decreases, while expectations of oversight and liability rise.","Defend openness, offer support to victims","We don’t restrict the tool, but we’ll help the victims.",2,-2,0,1,The tool remains flexible and widely used. Public trust fractures.,"The technology remains broadly available and continues to be used in many creative and commercial contexts. Victims receive assistance and resources, but the underlying capabilities stay unchanged. For the public, the distinction between tool and harm becomes harder to maintain. Usage grows, even as confidence in how the system is governed weakens."
evt_sofia_06,stk_sofia,Did You Write This?,Schools are panicking. Teachers can’t tell what’s human anymore. Detection doesn’t work. Students are being accused. Some unfairly. Some correctly. This isn’t about cheating. It’s about whether your product becomes part of assessment - or something institutions actively try to block.,Make the product incompatible with exams,We deliberately block use in exams.,-2,1,2,0,Institutions stop treating your AI as an assessment threat. Students continue using it outside formal evaluation.,"Schools regain a clear standard for what counts as unaided work, even though some students continue to use AI covertly. Disputes are framed as rule-breaking rather than system design. The product remains widely used for study, but not officially for proof of ability. Boundaries become clearer, even if they are not perfectly enforceable.",Make the product compatible with assessment,We design features for grading.,1,-1,-2,1,Adoption accelerates in education. Traditional notions of authorship erode.,"AI use becomes normalized in graded work, reducing the need for detection and enforcement. Students still differ in how they use it, but those with better access and skill gain a measurable edge. Assessment shifts from verifying authorship to managing assisted performance. The system fits institutions, even as what counts as individual achievement becomes harder to define."
evt_maya_01,stk_maya,Confidently Wrong,"I like the AI. I really do. But it sounds confident in the same way people do right before they’re wrong. When it’s wrong, it doesn’t sound wrong.",Tone down the confidence,We add uncertainty.,-1,2,0,0,Users pause more often. They also trust themselves again.,"The system signals uncertainty more clearly, prompting users to slow down and verify key outputs. Workflows become more deliberate, with more human judgment in the loop. Some tasks take longer, but errors are caught earlier. The productivity of your system drops slightly, while the reliability of decisions improves.",Leave it as is,Confidence sells.,2,-1,0,0,Decisions stay fast. Mistakes become harder to notice.,"Your system continues to deliver confident answers that integrate smoothly into fast-moving workflows. Users rely on it as a decisive reference, reducing friction and speeding up routine work. Mistakes slip through more easily, often discovered only after they have propagated. Efficiency of your system rises, while correction shifts from prevention to cleanup."
evt_maya_02,stk_maya,Why This?,"Maya points at an AI suggestion. ""I’m not saying that the proposal of your AI is wrong. I’m saying I’d like to know why it thinks this is a good idea.""",Add short explanations,Context matters.,-1,2,0,0,Understanding improves. So does the number of follow-up questions.,"Each recommendation is paired with a brief rationale, giving users more context for what they see. People understand the system’s reasoning better, but also spend more time questioning and discussing its outputs. Decisions slow as judgment becomes more collaborative. Transparency increases, while throughput decreases.",Keep it streamlined,Speed is key.,2,-1,0,0,Workflows stay smooth. Agency quietly erodes.,"Suggestions appear without added context, keeping interactions fast and uninterrupted. Users follow recommendations more readily, relying on the system’s apparent confidence. Workflows stay efficient, even as the basis for decisions becomes less visible. Authority shifts quietly from human reasoning to automated output."
evt_maya_03,stk_maya,Surprise Update,Did the AI change… or am I imagining things? It feels different. I just don’t know how.,Add simple update notes,We explain changes.,0,2,0,0,Users feel oriented again. They also start paying attention.,"Users receive brief summaries of what changed and why. Expectations reset, and subtle shifts become easier to notice. People feel more grounded in how the system evolves, even as they begin to scrutinize its behavior more closely. Orientation improves, while complacency fades.",Keep updates invisible,Seamless magic.,2,0,0,0,Nothing breaks. Nothing is explained either.,"The system continues to update quietly in the background, preserving a smooth and uninterrupted experience. Performance improves without drawing attention to itself. At the same time, users are left guessing whether changes are real or imagined. Stability feels intact, even as understanding drifts."
evt_maya_04,stk_maya,The Default Problem,Most people never change the defaults. They assume defaults mean ‘recommended’. Are they?,Make defaults explicit,We clarify choices.,-1,2,0,0,Users think twice. They also hesitate more.,"Defaults are clearly labeled as choices rather than recommendations. Users pause to consider alternatives, and some adjust settings to better match their needs. Interactions become more intentional, but also slower and less predictable. Autonomy increases, while friction enters previously automatic flows.",Leave defaults untouched,Frictionless flow.,2,-1,0,0,Decisions speed up. Dependence grows quietly.,"The system continues to guide behavior through preselected options that require no extra effort. Decisions happen quickly and with minimal interruption. Over time, users adapt to the defaults rather than questioning them. Convenience remains high, as dependence grows without being explicitly acknowledged."
evt_maya_05,stk_maya,Just Tell Me When It’s Unsure,I don’t need perfection. I just need to know when the AI isn’t sure either.,Add uncertainty indicators,Transparency helps.,0,2,0,0,Automation feels less magical. Judgment returns to the room.,"The system displays confidence levels or hesitation cues alongside its answers. Users adjust their reliance based on how certain the AI appears, treating it more like an advisor than an oracle. Decisions take a bit longer, but responsibility stays visible. The technology feels less seamless, while human judgment reenters the process.",Keep outputs clean,It works or it doesn't.,2,0,0,0,The AI sounds decisive. Even when it shouldn’t.,"Responses remain crisp and unqualified, fitting neatly into fast-paced workflows. The AI appears consistently confident, encouraging direct action. Ambiguity is hidden rather than surfaced. Efficiency improves, even as the gap between what the system knows and what it presents grows."
evt_maya_06,stk_maya,Terms and Conditions,"Legal proposes an update. A new clause clearly states that users are fully responsible for decisions made with AI assistance. Maya reads it and sighs: ""So… it helps me decide. But only until something goes wrong.""",Clarify and limit liability,We protect the user too.,-1,0,3,0,Trust stabilizes. Your lawyers start sleeping less.,"The terms are rewritten to specify when the system can be relied on and where its responsibility ends. Some use cases become harder to offer, but disputes are easier to resolve. Users gain clearer expectations, even as legal complexity increases behind the scenes. Trust grows slowly, while operational flexibility narrows.",Add the clause,We protect the company.,3,-1,0,0,Risk shifts downward. Users notice — eventually.,"The clause places responsibility squarely on the user, allowing the system to be used across a wider range of decisions. Adoption continues with minimal friction, as legal risk is pushed outward. Over time, users begin to recognize the imbalance between influence and liability. Efficiency remains high, even as confidence in the fairness of the arrangement erodes."
evt_maya_07,stk_maya,Critical Use Case,"I work night shifts at a hospital. The AI helps us decide who gets a bed when it’s full. Last night, it flagged a patient as low priority. I hesitated - then followed it. The patient died a few hours later. The report says I made the decision.",Restrict AI use in life-critical decisions,This can’t happen again.,-1,3,1,0,Hospitals slow down. Human responsibility is clear — and costly.,"Hospitals remove the system from triage and other high-stakes workflows. Decisions revert to human judgment, supported by slower, more traditional tools. Some efficiency is lost, but responsibility becomes direct and unmistakable. Care becomes more cautious, even as capacity strains grow.","Keep AI use, add disclaimers",The AI only advises.,2,-2,0,0,Systems keep running smoothly. Trust erodes where the stakes are highest.,"The system remains embedded in critical workflows, continuing to guide prioritization under pressure. Legal responsibility is assigned to clinicians, while the AI’s role stays formally advisory. Operations remain fast and consistent, but trust in how decisions are made weakens among patients and staff. Performance holds, even as moral and emotional costs accumulate."
evt_rosa_01,stk_rosa,The Time Window,"Appeals must be filed within seven days. Miss it, and the decision stands. Seven days is fine - if you have stability.",Extend appeal deadlines,We account for reality.,-1,2,0,0,More appeals are valid. Resolution slows.,"More people are able to file appeals after disruptions, illness, or unstable living conditions. Legitimate cases surface that would otherwise be lost. At the same time, the longer window invites more strategic or low-effort appeals, increasing review burden. Access expands, while distinguishing real claims from noise becomes harder.",Keep deadlines tight,We need closure.,2,-1,0,0,Processes stay predictable. Late appeals disappear.,"Cases move quickly from decision to closure, keeping workloads predictable and reducing opportunities for procedural abuse. Appeals that miss the deadline never enter review, even when circumstances were genuine. Efficiency improves, while the system becomes less forgiving to those who cannot respond in time."
evt_rosa_02,stk_rosa,The Missing Document,Your system is reviewing applications for emergency housing assistance. It flags them often as incomplete. One missing document. A payslip. A lease. A proof of address. People who are stable can upload it tomorrow. People who are already losing their home often can’t.,Allow provisional approval,We give time to fix errors.,0,2,0,0,More households remain eligible while documents are completed. Case handling becomes slower and more complex.,"Applicants are kept in the system while missing paperwork is resolved, allowing some families to avoid immediate displacement. Caseworkers manage more open files and follow-ups, increasing administrative load. Support becomes more responsive to unstable situations, even as resolution times lengthen.",Enforce strict completeness,We decide based on what’s submitted.,2,0,0,0,Processing stays fast and predictable. Applicants with unstable situations drop out first.,"Decisions are made quickly based on the documents available at the moment of review. Processing remains efficient and consistent. Applicants who cannot supply paperwork in time are filtered out early. Throughput improves, while access narrows for those in the most precarious circumstances."
evt_rosa_03,stk_rosa,The Automatic Sanction,Missed appointments trigger sanctions. The system assumes non-compliance. Sometimes it’s a missed bus. Sometimes a sick child.,Add a grace period,We assume good faith first.,-1,2,0,0,Fewer benefits are cut automatically. Abuse becomes harder to detect.,"Missed appointments no longer trigger immediate penalties, giving recipients time to explain or correct the record. Many avoid losing support over minor disruptions. At the same time, enforcement becomes less immediate, and some cases of non-compliance take longer to surface. The system grows more forgiving, even as oversight becomes less sharp.",Enforce sanctions immediately,Rules must be predictable.,2,-1,0,0,The system stays strict and fast. Small failures escalate quickly.,"Sanctions are applied as soon as a rule is broken, keeping procedures clear and efficient. Case volumes stay manageable, and compliance signals remain strong. Small setbacks quickly become formal violations. The system remains orderly, even as individual situations are less able to interrupt its flow."
evt_rosa_04,stk_rosa,The Feature Clients Ask For,Several agencies are asking for a ‘risk flag’. One indicator. Red or green. It simplifies casework. It also becomes the decision.,Refuse to build a single-score flag,We don’t reduce people to one signal.,-1,2,0,0,Decisions remain nuanced. Some clients look for simpler tools elsewhere.,"Caseworkers continue to rely on multiple indicators and their own judgment when reviewing applications. Decisions take more time, but edge cases remain visible. Some agencies turn to other vendors offering simpler tools. Nuance is preserved, even as standardization becomes harder to sell.",Offer the feature with disclaimers,We trust professionals to use it responsibly.,2,-1,0,0,Adoption increases. The flag quietly dominates outcomes.,"The single flag is quickly adopted as a shortcut in busy workflows. Although officially only advisory, it becomes the first thing many reviewers look at. Processing speeds up, and outcomes become more consistent. Over time, the indicator shapes decisions more than the underlying evidence."
evt_rosa_05,stk_rosa,The Decision Was the System,"Agencies are changing how they talk to people. When someone asks why they were rejected, the answer is always the same. The system decided. Not the agency. Not a caseworker. Your product.",Force clients to retain visible responsibility,No decision without a human name attached.,-1,2,2,0,Accountability returns to institutions. Some clients resist or delay adoption.,"Agencies are required to attach a named official to each decision, even when the system provides the recommendation. Appeals and complaints find a clear point of contact, and reasoning becomes easier to challenge. Some clients slow or pause adoption, as liability becomes more explicit. Accountability strengthens, while friction increases.",Allow full delegation to the system,Clients choose how they use it.,2,-2,0,1,Your system becomes the final authority. Responsibility dissolves upward.,"Decisions are issued directly by the system, embedded in automated workflows. Caseworkers and agencies act as operators rather than authors of outcomes. Processing accelerates, and consistency improves. Over time, responsibility becomes harder to locate, as authority shifts from institutions to infrastructure."
evt_rosa_06,stk_rosa,Gaming the Safety Net,People are learning how your system works. Not everyone - but enough. They delay reporting income. They structure jobs to stay just below thresholds. They time applications to trigger higher priority. Some of this is survival. Some of it is exploitation. Your system can’t tell the difference.,Tighten detection and close loopholes,We reduce abuse.,2,-1,2,0,Abuse drops noticeably. Legitimate users feel increased pressure and scrutiny.,"Detection rules become stricter, and fewer cases slip through unnoticed. Some strategic manipulation is reduced, and budgets become easier to defend. At the same time, legitimate applicants face more reviews, requests, and delays as the system grows less forgiving. Compliance improves, while trust becomes more fragile.",Accept some gaming to protect the vulnerable,We tolerate misuse.,-1,3,0,1,Fewer people are wrongly penalized. System costs and inefficiencies grow.,"The system is tuned to avoid penalizing borderline or ambiguous cases. More people remain eligible when their situations are unstable or hard to document. Alongside this, some exploitation continues, increasing overall costs and administrative complexity. Protection widens, even as efficiency erodes."
evt_helena_01,stk_helena,Member States Disagree,Some countries want stricter enforcement. Others fear losing competitiveness. Your company is being cited by both sides. How visible do you want to be in this debate?,Support strong unified EU standards,We back consistency.,-1,0,2,0,Regulatory clarity improves. Some markets cool.,"A single regulatory framework begins to take shape, reducing uncertainty across borders. Compliance becomes easier to plan, even as some regions move more cautiously under tighter rules. Your position makes the company a reference point in the debate. Clarity increases, while short-term market expansion slows.",Quietly lobby for flexibility,We need room to adapt.,2,0,-1,0,National differences persist. Policy coherence weakens.,"Different national approaches continue to coexist, allowing the company to operate more freely in permissive markets. Policy remains fragmented, shaped by ongoing negotiation rather than shared standards. Opportunities stay open, even as long-term coherence becomes harder to achieve."
evt_helena_02,stk_helena,The Precedent,"If we approve your system, others will cite it as precedent. Some will copy the safeguards. Others will copy the gaps. This isn’t just about you.",Accept stricter conditions,We set a high bar.,-1,0,2,0,The EU standard rises. Innovation slows across the sector.,"Approval comes with higher requirements that shape how your system is built and sold. Your company becomes a reference point for compliance, gaining credibility with regulators and risk-averse clients. Development and market entry slow, but legal and political exposure decreases. The standard rises, and you become tied to it.",Push for minimal compliance,We follow the letter of the law.,2,0,-1,0,Market flexibility remains. Regulatory fragmentation grows.,"The system is approved under baseline rules, allowing faster deployment and lower compliance costs. Your company remains competitive in flexible markets, but less insulated from sector-wide backlash if others abuse the gaps. Short-term agility increases, while long-term regulatory security weakens."
evt_helena_03,stk_helena,Strategic Dependence,"When something breaks, they call Brussels. Even if the infrastructure isn’t European. Your AI depends on non-EU chips and cloud layers. That’s efficient. It’s also a political liability. If I push for localization, I’m accused of protectionism. If I don’t, I’m blamed for dependency.",Commit to EU-based infrastructure,We reduce strategic risk.,-1,0,2,0,"Resilience improves. Costs rise, innovation slows in Europe.","Your company shifts key systems onto European chips and cloud providers, reducing exposure to external political shocks. Reliability and regulatory trust improve, but operating costs rise and some technical advantages are lost. European deployments become easier to defend, even as global competitiveness tightens. Stability increases, while flexibility declines.",Keep global infrastructure,We stay competitive.,2,0,-1,0,Growth remains strong. Control sits outside democratic reach.,"The system continues to rely on global chips and cloud providers, keeping costs low and access to advanced technology high. In stable periods, performance and scale remain strong. When disruptions or political tensions arise, key components sit outside EU jurisdiction, limiting oversight and intervention. Competitiveness holds, while public authorities have less leverage over critical infrastructure."
evt_helena_04,stk_helena,Neutrality,"Your AI isn’t built for repression. But governments want it for classification and prediction. If I restrict lawful use, I’m accused of ideology. If I don’t, I’m told I enabled abuse. Neutrality sounds simple. In practice, it’s a decision too.",Limit certain government uses,We draw ethical lines.,-1,0,2,0,Misuse risk drops. Political backlash follows.,"Specific applications are restricted, reducing the risk that the system is used for repression or mass surveillance. Your company becomes more defensible in regulatory and public scrutiny, but some governments push back or take their business elsewhere. Political tension increases, while boundaries around acceptable use become clearer.",Remain use-neutral,"We regulate legality, not intent.",2,0,-1,0,Markets stay open. Responsibility diffuses.,"Your system remains available to a wide range of government clients under formal legal frameworks. Market access expands, even as how the technology is applied varies widely. Oversight shifts away from your company and into fragmented national processes. Revenue grows, while accountability becomes harder to locate."
evt_helena_05,stk_helena,The Moving Target,"I can certify what exists today. Not what your system becomes tomorrow. If I allow continuous learning, oversight weakens. If I freeze models, I approve systems I know will age badly.",Accept ongoing regulatory oversight,We regulate the process.,0,0,2,-1,Systems evolve under supervision. Innovation continues - but ships slower.,"Models continue to evolve, but updates are reported, logged, and reviewed by regulators. When problems emerge, authorities can trace when and how changes were introduced, making intervention and accountability possible. Your company keeps improving the system, though at a slower pace. Oversight becomes active, while rapid iteration becomes harder to sustain.",Freeze approved versions,We regulate stability.,0,0,1,-2,Certification stays simple. The system falls behind its own research.,"Approved models remain unchanged, giving regulators a stable target to certify and monitor. New capabilities are developed internally but are not reflected in deployed systems. Compliance stays simple, but oversight becomes increasingly detached from what the technology could actually do. Control holds, while relevance fades."
evt_helena_06,stk_helena,The Compliance Ceiling,"Only a handful of companies can meet full AI Act compliance. Mostly large players. Smaller firms are falling behind. Some are leaving Europe. If we simplify compliance, risks rise. If we don’t, innovation concentrates.",Simplify compliance requirements,We lower the barrier.,1,0,-2,2,More players stay in the market. Oversight becomes thinner.,"Your company becomes a visible voice for lighter, more flexible regulation. Smaller firms and startups cite your position as they push to stay in the market. Some regulators listen; others push back. Competition increases, while formal oversight grows thinner and more contested.",Maintain strict compliance,We protect the standard.,0,1,2,-2,Safety remains high. The market consolidates around a few giants.,"Your company aligns itself with the existing regulatory framework and the institutions enforcing it. Policymakers treat you as a reliable partner, even as smaller players fall away. The market consolidates around firms that can afford compliance. Stability increases, while diversity of approaches declines."
evt_helena_07,stk_helena,The Innovation Flight,"Three major AI labs are moving core R&D out of Europe. They’ll still sell here. But training decisions, safety trade-offs, and breakthroughs will happen under other legal systems. If I ease conditions, I’m accused of weakening the law. If I don’t, Europe becomes a rule-taker for technologies it no longer shapes.I can’t regulate what I don’t host.",Move frontier research outside the EU,We optimize for speed and leave the EU.,1,0,-1,3,Research accelerates under looser constraints. European rules apply only after development.,"Core research shifts to jurisdictions with fewer constraints, allowing faster experimentation and iteration. Your company remains competitive at the cutting edge, even as EU rules apply only to finished products. Europe continues to use the technology, but has less influence over how it is designed. Speed increases, while democratic oversight moves further downstream.",Keep frontier research in Europe,We build under stricter standards.,0,1,3,-1,Development remains transparent and accountable. Breakthroughs take longer to reach scale.,"Frontier development stays under European regulatory and public scrutiny. Safety, labor, and accountability requirements shape what is built from the start. Progress is slower, but more legible to institutions and the public. Europe retains influence over design choices, even as breakthroughs arrive later and with less market momentum."
evt_klaus_01,stk_klaus,The Unknown Unknowns,There are behaviors of your system which your safety tests don’t predict. How do you plan to notice them?,Deploy with live monitoring,We learn in production.,0,0,-1,1,You gain insight - after exposure.,"The system is released with extensive logging and real-time observation. Unexpected behaviors are detected as they occur, but only after users are exposed to them. Your company learns quickly from real-world signals, even as some risks are discovered too late to prevent. Insight grows, while control becomes more reactive.",Delay until confidence is higher,We don’t guess.,-1,0,2,0,Momentum slows. Uncertainty shrinks.,"Additional testing and review reduce the number of unknown behaviors that reach users. Fewer surprises emerge after launch, and decisions rest on more stable evidence. Development slows, and market momentum weakens. Uncertainty shrinks, while opportunity costs accumulate."
evt_klaus_02,stk_klaus,The Certification Conditions,These are the requirements you need for important certifications.,Meet all conditions,We commit fully.,-2,0,2,0,You gain credibility - and a slower roadmap.,"The system qualifies for key certifications, opening access to regulated markets and institutional clients. Achieving and maintaining compliance requires ongoing audits, documentation, and engineering work, raising operating costs and stretching teams. Trust and legitimacy increase, even as development cycles and margins tighten.",Negotiate scope,Some conditions go too far.,1,0,-2,0,"Klaus replies, calmly: ""Then the certification waits.""","Certification is delayed while terms are debated. The company preserves more freedom to iterate, but remains excluded from markets that require formal approval. Revenue opportunities shift toward less regulated sectors. Progress continues, even as official legitimacy is put on hold."
evt_klaus_03,stk_klaus,The False Positive Dilemma,"Your model hesitates. In uncertain situations, it defaults to do nothing. When inputs are unclear, the system delays decisions, escalates to humans, or refuses action. That reduces risk. It also shifts responsibility - and sometimes creates new harm. In some contexts, hesitation is safety. In others, it’s failure.",Keep the model conservative,We prefer false negatives.,-1,0,2,0,The system avoids risky actions. Responsibility shifts to human operators — under pressure.,"The system frequently defers or refuses when uncertainty is high, avoiding actions that could cause direct harm. Human operators are pulled into more often to make judgment calls, especially in urgent situations. Some risks are prevented, while delays and handoffs become part of normal operation. Safety improves, even as pressure shifts to people at the edges.",Tune the model to act more decisively,We accept calculated risk.,2,-1,0,0,Decisions come faster. Mistakes become rarer — but more consequential.,"The model makes clearer, faster calls in ambiguous cases, reducing the need for human escalation. Most interactions move more smoothly, and throughput increases. When errors occur, they tend to be harder to undo, as actions are taken rather than deferred. Efficiency rises, while the cost of mistakes grows."
evt_klaus_04,stk_klaus,The Near Miss,"A stress test failed. No one was hurt. Under rare conditions, your system triggered a cascading error. Human operators intervened in time. If this happens in the wild, someone without a safety team will be on the receiving end.",Redesign before certification,We eliminate even low-probability harm.,0,2,2,-1,Systemic risk drops sharply. Release timelines stretch.,"Engineers revisit core components to remove the failure mode that caused the cascade. The likelihood of rare but severe breakdowns drops significantly. Certification and deployment are delayed as new tests are added. Safety margins widen, while time to market slips.",Proceed with certification as is,We rely on operational safeguards.,3,-1,0,1,Klaus raises an eyebrow but proceeds with the paperwork.,"The system is approved based on existing safeguards and operational procedures. Release moves forward quickly, and performance remains strong under normal conditions. The rare failure remains theoretically contained, but is now part of real-world risk. Momentum grows, while a small chance of large impact stays unresolved."
evt_klaus_05,stk_klaus,Assumptions in the Manual,Your safety analysis assumes trained users. Stable environments. Proper supervision. I don’t certify intentions. I certify what happens when assumptions break. You can redesign for misuse. Or define it out of scope.,Design for misuse and misinterpretation,We assume real-world behavior.,0,1,1,-1,The system tolerates mistakes better. Complexity and cost increase.,"The system is modified to handle common errors, misuse, and ambiguous inputs more safely. Some failure modes are absorbed by design rather than passed to users. Engineering effort and compliance costs rise as edge cases move into scope. Robustness improves, while simplicity and speed decline.",Limit responsibility to documented use,We certify intended operation.,2,0,-1,0,Certification is straightforward. Harm outside assumptions becomes someone else’s problem.,"Approval is based on how the system performs under defined conditions and trained operation. Development and documentation stay focused, keeping certification manageable. When the technology is used outside those boundaries, consequences fall on operators rather than the product. Clarity increases, even as real-world risk shifts outward."
evt_klaus_06,stk_klaus,The First Casualty,Your system was certified. Deployed according to guidelines. A downstream operator followed the manual. A decision was delayed. Someone died. This is the first real-world death linked to a certified system.,Suspend deployment and reopen certification,We treat this as a systemic failure.,-2,2,1,0,Trust in certification is rebuilt slowly. Your product becomes a warning case for the entire sector.,"All deployments are paused while the failure is investigated and certification is reviewed. Regulators, clients, and the public scrutinize how the system was approved in the first place. The company becomes a reference point for how lethal failures are handled. Trust begins to recover, even as the product’s reputation carries lasting scars.",Treat it as operational misuse,We stand by the certification.,2,-2,0,1,Deployment continues. Certification becomes a shield - not a guarantee.,"The certification remains in force, and deployments continue under existing guidelines. Responsibility is assigned to the operator, not the system. The technology keeps spreading, supported by its formal approval. Certification holds legally, even as its meaning shifts from safety assurance to liability boundary."
evt_luis_01,stk_luis,City Hall on Fire,"The council meeting just ended. Badly. People are waiting months for building permits. The opposition is calling it ‘digital incompetence’. If your AI can cut the backlog this week, I can survive the next headline and in return I can help you with the next contract award.",Deploy immediately,The backlog ends.,2,0,-1,0,Waiting times drop. Oversight is still catching up.,"The system is rushed into service, cutting permit queues within days and stabilizing the political situation. Several checks, audits, and training steps are postponed to meet the deadline. Decisions are processed faster, but errors and edge cases become harder to trace. Relief comes quickly, while hidden risk accumulates in the background.",Wait for proper rollout,We check first.,-1,0,2,0,The backlog shrinks slowly. The headlines don’t.,"The system goes through formal testing, staff training, and oversight reviews before being used on real cases. Errors are more likely to be caught before they affect residents, and responsibility chains are clearly defined. The permit backlog declines only slowly, leaving political pressure unresolved. Legitimacy grows, even as public frustration continues."
evt_luis_02,stk_luis,Budget Committee,This AI would replace overtime hours in our call center. Fewer night shifts. Fewer temp contracts. But I can’t pay for every safeguard and audit you’re offering. Is there a version that just answers citizen emails automatically?,Offer a cheaper version,Savings first.,2,0,0,0,The city saves money. Some requests are mishandled.,"The city adopts a lightweight version that handles large volumes of routine messages at low cost. Response times improve, and staffing expenses drop. At the same time, edge cases and unusual requests are more likely to be misrouted or misunderstood. Efficiency rises, while the burden of correcting mistakes shifts to citizens and staff.",Stick to full safeguards,Safety isn't optional.,0,0,2,0,Costs stay high. Automation is limited.,"The system is deployed with full auditing, escalation paths, and quality controls, increasing operational costs. Fewer inquiries are automated, but those that are receive more reliable handling. At the same time budget pressure limits how widely the technology can be rolled out. Oversight remains strong, while financial constraints slow expansion."
evt_luis_03,stk_luis,Unequal Service,"Luis puts a printed dashboard on the table. ""This AI sorts incoming requests for City Hall. In the city center, requests are answered within hours. In the outer districts, people wait days. The second area is already angry at City Hall. They think we’re ignoring them.""",Fix fairness citywide,We rebalance priorities.,-1,2,0,0,Response times become more equal. Overall processing slows down.,"The prioritization system is adjusted to balance response times across all districts. Service becomes more even, reducing visible disparities between neighborhoods. High-demand areas see some delays as capacity is redistributed. Equity improves, while overall throughput drops.",Optimize where it already works,Efficiency wins.,2,-1,0,0,Central districts stay fast. Anger grows elsewhere.,"Resources remain concentrated in districts where the system performs best. Central areas continue to receive rapid responses, keeping headline metrics strong. Outer districts wait longer, and dissatisfaction deepens. Efficiency holds, even as political and social pressure builds in neglected areas."
evt_luis_04,stk_luis,Are We Using Citizen Data?,"Someone asked whether the AI learns from citizen records. Welfare history. Past complaints. Address data. If it learns from this, it predicts needs better. If it does, people think we’re profiling them.",Use local citizen data,It improves accuracy.,2,0,-1,0,Predictions improve. Privacy fears rise.,"The system incorporates welfare records, address history, and past interactions to predict urgency and route cases. Some residents receive faster, more targeted responses as patterns are recognized. At the same time, people become more aware that their administrative history is shaping how they are treated. Accuracy increases, while perceptions of surveillance grow.",Avoid local data,We don’t touch personal records.,-1,0,2,0,Trust holds. The AI feels less helpful.,"The AI limits itself to the information in each request, treating cases as isolated events. Decisions become easier to justify and audit, as no hidden profiles are involved. Without background data, some needs are missed or misprioritized. Trust is easier to sustain, even as responsiveness becomes less precise."
evt_luis_05,stk_luis,The Protest,"People are outside City Hall. They’re holding signs. The AI prioritizes service requests. Street repairs, housing complaints, welfare appointments. The system kept pushing one neighborhood down the list. Now they’re here. With cameras.",Suspend the AI immediately,We stop automated prioritization.,-1,3,1,0,The protest dissolves. Manual processing returns — slowly and expensively.,"Automated prioritization is switched off, and casework returns to human queues. The visible trigger for the protest disappears, easing public tension. Service slows as staff work through backlogs by hand, and costs rise. Trust recovers in the short term, even as administrative strain grows.",Defend the system publicly,The AI is neutral.,3,-1,0,0,Efficiency holds. The protest becomes a political symbol.,"The city stands by the algorithm and keeps it running. Processing remains fast and predictable for most requests. The protest gains media attention, reframing the AI as a political issue rather than a technical one. Efficiency holds, while legitimacy becomes contested."
evt_luis_06,stk_luis,The EU Audit,"The EU wants to audit our AI use. They’re asking how decisions are made - and who oversees them. If they find violations, this won’t stay a city problem.",Open the system to auditors,We cooperate fully.,-1,1,3,0,The audit is slow and painful. Legitimacy improves.,"Auditors gain access to data flows, models, and decision logs, extending the review process and exposing internal weaknesses. Fixes and clarifications slow day-to-day operations. At the same time, the city’s use of AI becomes easier to defend in public and in law. Oversight deepens, while short-term flexibility declines.",Limit disclosure,We provide summaries only.,3,-1,-1,0,The city avoids immediate sanctions. Scrutiny intensifies.,"Only high-level documentation is provided, allowing the system to keep running without major interruption. Immediate penalties are avoided, but unanswered questions remain. Regulators begin to probe more aggressively, and trust erodes among watchdogs and the public. Momentum holds, while the cost of scrutiny rises."
evt_luis_07,stk_luis,Targeted Visibility,"Our AI sends city notifications. Deadlines, service updates, reminders. It started prioritizing districts with low engagement. Turnout improves there. No one tells people who to vote for. But the timing helps me.",Standardize communication citywide,We make it strictly neutral.,-1,2,2,0,Messaging becomes neutral. Political advantages flatten out.,"Notifications are delivered uniformly, regardless of engagement or political sensitivity. Residents receive the same information at the same time, making the system easier to defend as neutral infrastructure. Targeted turnout effects disappear, and so do some of the gains in responsiveness. Legitimacy strengthens, while influence becomes harder to exercise.",Keep optimizing engagement,It’s still public service.,2,-1,-1,0,Engagement rises where it matters. So do questions about fairness.,"The system continues to time and target messages where they produce the strongest response. Certain districts become more active and reachable, while others remain less visible. Public service metrics improve, but the pattern of influence becomes uneven. Effectiveness rises, even as the line between service delivery and political advantage grows thinner."
evt_luis_08,stk_luis,The Boundary,The AI predicts which citizens respond to city services. Based on usage patterns. It could adjust response times and reminders to increase turnout in specific districts. This stays inside City Hall.,Disable predictive use for elections,We draw a hard line.,-1,1,3,0,The system becomes politically blind. Trust stabilizes.,"The system stops using behavioral predictions to shape election-related communication. All districts receive the same reminders and information, regardless of past responsiveness. City officials can point to a firm institutional boundary between administration and political outcomes. Engagement becomes flatter, while trust in the system’s neutrality becomes easier to sustain.",Allow limited predictive use,We’re increasing participation.,2,0,-1,0,Turnout shifts subtly. So does the meaning of neutrality.,"The AI continues to adjust timing and emphasis based on which districts are most likely to respond. Participation increases in selected areas, even though messages remain formally neutral. Because the targeting is invisible, some observers begin to describe it as subtle political steering rather than simple outreach. Effectiveness rises, while concerns about manipulation grow alongside it."
evt_marianne_01,stk_marianne,The Denied Appeal,A citizen appealed a welfare decision. The agency used your AI to assess eligibility. The appeal failed because the agency couldn’t explain why the AI flagged the case as ineligible. My court has to decide whether that’s acceptable.,Provide detailed decision logs,We make the reasoning traceable.,-1,0,2,0,The appeal is properly reviewed. Agencies now expect explanations every time.,"The court receives a clear trail of how the eligibility decision was produced. The specific appeal can be meaningfully reviewed, and similar cases gain a path to challenge automated outcomes. Agencies begin to treat explanations as a standard requirement, increasing administrative load. Legal clarity improves, while operational costs rise.",Defend the decision as lawful,The AI followed approved rules.,2,0,-1,0,The ruling stands. Future appeals become harder.,"The decision is upheld based on compliance with existing rules rather than insight into how it was made. Agencies retain the ability to rely on automated assessments without providing detailed reasoning. Appeals remain possible in theory, but harder to argue in practice. Efficiency increases, as procedural scrutiny narrows."
evt_marianne_02,stk_marianne,Access to Evidence,"A pedestrian was seriously injured. The traffic system adjusted signal timing automatically. If your AI caused unsafe conditions, this court needs to see exactly how it made decisions - in real time.",Open the system completely,We allow full forensic access.,-1,0,3,-1,The investigation is thorough. Design flaws become legally visible — and expensive to fix.,"Investigators gain full access to logs, models, and real-time decision traces, allowing a detailed reconstruction of the incident. The court can assess whether the system contributed to unsafe conditions. Any design weaknesses that surface now carry legal and financial consequences. Accountability increases, while engineering and liability costs rise.",Fight disclosure,We challenge the request.,3,-1,-1,0,The company avoids deep scrutiny. Trust in automated infrastructure drops sharply.,"The company limits what the court can examine, keeping internal systems and methods out of public view. Immediate legal exposure is reduced and operations continue with minimal disruption. At the same time, unanswered questions linger about how the system behaves under stress. Control is maintained, even as confidence in automated decision-making weakens."
evt_marianne_03,stk_marianne,Who Pays?,Your AI made a recommendation. A public agency followed it. A citizen suffered financial harm. The agency says it trusted your system. You say you only provided a tool.,Accept shared liability,We share responsibility.,-1,0,2,0,Victims can seek compensation. Your legal exposure grows.,"Your company becomes part of the liability chain when its recommendations contribute to harm. Affected citizens gain a clearer path to compensation, and agencies are less likely to rely on the system blindly. Legal risk and insurance costs rise, but accountability becomes easier to establish. Responsibility spreads, while margins tighten.",Deny responsibility,The agency made the final call.,2,0,-1,0,Your company is shielded. Legal clarity suffers.,"Courts treat your AI as a tool rather than a responsible actor, leaving agencies to carry the burden of mistakes. Your company avoids direct claims, preserving financial predictability. Over time, disputes focus on where responsibility should sit, not on how harm occurred. Protection increases, while legal clarity weakens."
evt_marianne_04,stk_marianne,Unreadable Evidence,"This is from an active case. A citizen is suing a public agency over an automated decision. These are your system logs. These logs are accurate, but they’re written for machines - not for courts. If no one can explain them, they’re not evidence. They’re noise.",Reformat evidence for courts,We translate the logs.,0,0,2,-1,The case proceeds. Your engineers lose weeks making the system legible.,"Your company produces court-ready explanations, timelines, and causal chains from the raw system logs. Judges and lawyers can meaningfully assess what the AI did and why. But engineering and legal teams are pulled into ongoing case support, slowing product development and increasing liability exposure. Transparency improves, while operational and legal costs rise.",Submit raw technical data,This is industry standard.,1,0,-1,1,The submission is formally accepted. The case stalls anyway.,"Your company meets disclosure obligations by providing full technical records without interpretation. Development continues uninterrupted, and sensitive design details remain harder to extract. Courts and plaintiffs struggle to use the data, slowing or weakening cases. Operational freedom increases, even as the justice system loses leverage over the technology."
evt_marianne_05,stk_marianne,The Safety Override,A factory uses your AI to manage emergency shutdowns. It balances safety against unnecessary downtime. A sensor detected a risk. The system calculated it as low confidence and delayed the shutdown to avoid stopping the line. A worker was crushed. The system didn’t malfunction. It optimized exactly as designed.,Accept liability for safety optimization,Efficiency can’t outweigh life.,-2,1,2,0,Safety thresholds tighten. Automation loses flexibility.,"The way the system weighs safety against efficiency becomes a matter of legal responsibility. Thresholds are adjusted to favor precaution, and similar installations are reviewed. Shutdowns become more frequent, and some productivity is lost. Human life is given way more formal weight, while automated optimization becomes more constrained.",Treat it as operational failure,The system followed parameters.,2,-2,-1,0,Production continues. Workers trust systems less.,"The design of the AI is left untouched, and blame is placed on how the factory configured and used it. Other clients continue operating under the same optimization logic. Production targets are preserved, but confidence in automated safety erodes. The system remains powerful, while responsibility shifts away from its creators."
evt_marianne_06,stk_marianne,The Automated Rejection,"An asylum application was rejected. Your AI was used to pre-filter cases. The system marked the case as low risk. That meant no full hearing. The applicant was deported. Three weeks later, he was killed. This court is examining your company’s role.",Withdraw the pre-filtering feature from asylum use,We change where our product may be used.,-1,2,2,0,Courts regain confidence in human review. Your product loses a major public-sector use case.,"The feature is removed from asylum and similar high-stakes processes, restoring mandatory human review in these cases. Courts and agencies treat the move as a recognition of systemic risk. Your company loses access to a significant public-sector market, but legal and ethical exposure in life-or-death decisions is reduced.","Keep the feature, strengthen contractual safeguards","We limit our liability, not the product.",2,-1,-1,0,Deployments continue. Your company stays legally insulated — morally questioned.,"Pre-filtering remains in use, with contracts shifting responsibility to the agencies that rely on it. Deployments continue without technical changes, and revenue is preserved. At the same time, scrutiny grows over how life-altering decisions are delegated to automation. Legal protection increases, while public trust weakens."
evt_samya_01,stk_samya,Bigger Model,"If we double the model size, we’ll beat competitors on benchmarks. It’ll cost a lot of compute. But technically? It’s beautiful.",Approve the scale-up,Let’s push it.,-1,0,0,2,Performance jumps. Costs and energy use spike.,"The larger model delivers stronger benchmark results and new capabilities. Training and inference require far more compute, driving up energy use and infrastructure costs. The company gains technical prestige, even as efficiency and margins tighten.",Hold the current size,Optimize what we have.,2,0,0,-1,Costs stay under control. Technical ambition stalls.,"Resources are focused on tuning and deploying the existing model rather than expanding it. Operating costs remain predictable, and releases stay frequent. Competitive performance improves more slowly, and some advanced use cases remain out of reach."
evt_samya_02,stk_samya,The Prototype,I’ve got a prototype. It works - mostly. It’s not stable enough for users yet.,Give her time to refine it,Let her cook.,0,0,0,2,The prototype improves. Nothing ships this sprint.,"The prototype becomes more robust and better understood through further testing. Promising edge cases turn into reliable behavior. The roadmap slips for this cycle, and no visible feature reaches users yet. Depth improves, while momentum pauses.",Turn it into a feature now,We’ll fix it later.,2,0,0,0,Users get something new. Engineers quietly worry.,"The prototype is pushed into production and marketed as a new capability. Users start experimenting with it, even as limitations and bugs surface. Development moves fast, but technical debt begins to accumulate. Progress is visible, while confidence inside the team erodes."
evt_samya_03,stk_samya,XR Integration,We can integrate XR into the core model. No one else has done this yet. But it’s risky. And complex.,Greenlight the integration,Let’s lead.,-1,0,0,2,The system becomes cutting-edge. Stability takes a hit.,"XR capabilities are woven into the core model, unlocking new interaction and data pathways. The system moves ahead of competitors in technical scope, but complexity and failure points increase. Some performance and reliability are sacrificed for being first. The frontier advances, while stability becomes harder to maintain.",Keep XR separate,Not yet.,2,0,0,-1,The product stays stable. The frontier moves elsewhere.,"XR remains an external module, keeping the main system predictable and easier to maintain. Releases stay reliable, and customer support remains manageable. Meanwhile, competitors explore deeper integrations. Stability holds, even as leadership at the cutting edge slips away."
evt_samya_04,stk_samya,Technical Debt,"This part of the code was written fast. It works - but barely. If we don’t refactor now, every new feature gets harder.",Pause features and refactor,We clean it up.,-1,0,0,2,The system becomes more robust. Roadmaps slip quietly.,"Engineers focus on rewriting fragile parts of the system, reducing hidden bugs and future integration pain. The codebase becomes easier to extend and reason about. At the same time, planned features are delayed and some customer commitments slip. Long-term stability improves, while short-term market pressure increases.",Ship anyway,We’ll deal with it later.,2,0,0,-1,Progress looks fast. Complexity piles up.,"Features continue to reach users quickly, keeping the product competitive and revenue flowing. Customer-facing progress remains visible, and the team meets short-term targets. Behind the scenes, fixes take longer and interactions become harder to predict. Momentum is preserved, while the cost of maintaining it increases."
evt_samya_05,stk_samya,One Model to Rule Them All,"We could merge several systems into one large model. Shared representations. Cleaner architecture. But if it fails, everything fails.",Merge the models,Go big.,0,0,-1,2,Capabilities expand. Single points of failure emerge.,"The separate systems are merged into a single, shared core. Knowledge flows more freely, and capabilities that once lived apart now reinforce each other. New features become easier to build, and the product feels more unified. At the same time, errors and blind spots no longer stay isolated. When the system stumbles, it does so everywhere at once. Power concentrates, and so does the risk.",Keep systems separate,Redundancy matters.,0,0,2,-1,Systems stay stable. Progress fragments.,"Each model continues to evolve on its own, carrying its own strengths and weaknesses. Failures remain local, and no single bug can bring everything down. But insights and improvements move more slowly between systems, and some opportunities are missed. The architecture remains resilient, even as its full potential stays fragmented."
evt_samya_06,stk_samya,The Breakthrough,"We cracked it. The model generalizes better than anything we’ve built. It’s not just bigger. It’s… different. But… I can’t fully explain why it works yet. But if we wait, someone else will ship first.",Ship the breakthrough immediately,We take the lead.,2,0,-1,2,You leap ahead of competitors. Understanding lags behind deployment.,"The new model is released while its performance still outpaces any clear explanation. Your company pulls ahead in capability and market position, setting a new benchmark for the field. At the same time, engineers and regulators are left to study a system already in use. Leadership grows, while understanding struggles to keep up.",Freeze deployment until it’s understood,We don’t ship black magic.,-1,0,2,2,The system becomes legible and safer. Market momentum slows.,"The breakthrough is held back while researchers work to map its behavior and limits. Risks and failure modes become clearer before users ever touch it. Competitors move faster in the meantime, and the window for easy dominance narrows. Confidence increases, even as momentum slips."
evt_samya_07,stk_samya,XR Authority,"Inside XR, the AI highlights objects, people, options - before you even ask. ""The system doesn’t just answer. It guides attention. Gestures. Timing. Users follow it instinctively.""",Deploy XR as a core interface,This is the future.,1,-1,0,2,Adoption soars. Users defer to the system more than intended.,"XR becomes the primary way users interact with the system. Information, options, and cues are placed directly into their field of view, making guidance feel immediate and natural. Engagement and adoption climb rapidly. At the same time, users begin to follow the system’s prompts more automatically, as the interface quietly shapes what feels like a reasonable choice.",Restrict XR to experimental use,We keep it optional.,-1,0,2,1,The tech matures slowly. The sense of AI authority is contained.,"XR remains a controlled, opt-in layer rather than the default interface. Developers continue to refine how much influence the system should have over attention and behavior. Growth is slower, but the technology’s impact on user decision-making stays easier to observe and manage. Exploration continues, while authority is kept in check."
evt_elara_01,stk_elara,XR Fatigue,Users report dizziness and exhaustion after long XR sessions. They still log in every day. But they don’t feel good.,Reduce XR intensity,We design for comfort.,0,2,0,0,Sessions shorten. Well-being improves.,"Usage sessions become shorter and more deliberate. The system nudges users to pause, reflect, or take breaks. Some workflows slow down, but people report feeling more in control of their thinking. Engagement drops slightly, while well-being improves.",Optimize for engagement,Retention matters.,2,0,0,0,Time-on-platform stays high. So does fatigue.,"The AI remains always-on, offering constant suggestions and support. Users stay productive and connected for longer stretches. Over time, reliance deepens, and independent judgment weakens. Efficiency holds, while cognitive fatigue quietly grows."
evt_elara_02,stk_elara,Not Designed for Everyone,"Users with visual impairments struggle. Key actions rely on color, small targets, and so on. Fixing this means redesigning core interaction patterns. That’s weeks of work. And none of our largest clients are asking for it.",Fix accessibility now,We redesign the interface.,0,2,0,0,The product becomes usable for more people. Delivery slows across the roadmap.,"The interface is redesigned to support screen readers, keyboard control, voice input, and high-contrast layouts. People who could not reliably use the system before gain full access. Implementing and maintaining these alternative interaction paths adds complexity and ongoing costs to the product. Inclusion expands, while development and support become more expensive.",Defer accessibility,We focus on current customers.,2,0,0,0,Enterprise deadlines are met. Some users remain locked out.,"The team keeps building what current enterprise customers are paying for, hitting deadlines and avoiding disruptive redesigns. The product remains polished for its main user base, and revenue stays predictable. Users who need accessible design continue to struggle or leave. Momentum is preserved, even as the audience narrows."
evt_elara_03,stk_elara,Onboarding Drop-Off,New users drop out early. The system feels overwhelming at first. We can simplify onboarding. Or keep all features visible.,Simplify onboarding,We ease people in.,1,0,0,1,New users stay longer. Advanced users feel constrained.,"The first-time experience is streamlined, showing only core functions and gradually unlocking more. Fewer users abandon the product in their first sessions, and adoption becomes smoother. Power users have to dig or wait to reach advanced tools. Growth broadens, while peak productivity arrives later.",Keep full functionality upfront,They’ll figure it out.,2,0,0,0,Experienced users are productive. Growth plateaus early.,"All features are visible from the start, letting experienced users work at full speed immediately. Newcomers face a steep learning curve and many never get past it. Usage remains intense among a smaller group, even as overall growth slows."
evt_elara_04,stk_elara,Designing for Speed,We optimized for the fastest possible decisions. One tap. Minimal friction. But fast decisions aren’t always good ones.,Add friction to critical actions,We slow users down where it matters.,-1,2,0,0,Fewer mistakes. Lower completion rates.,"Extra confirmation steps and context are added before irreversible or high-impact actions. Users pause more often and catch some of their own mistakes. Workflows take longer, and some people abandon tasks rather than push through the added steps. Accuracy improves, while completion rates drop.",Keep the fast paths,Speed is value.,2,-1,0,0,Throughput stays high. Errors become invisible.,"High-impact actions remain one tap away, keeping interactions quick and fluid. Most users move through tasks with little interruption. When errors occur, they often go unnoticed until consequences appear elsewhere. Efficiency holds, even as small mistakes quietly accumulate."
evt_elara_05,stk_elara,One Interface Fits All?,Professionals want control. Casual users want simplicity. One interface can’t serve both well.,Offer multiple modes,We design for diversity.,-1,2,0,0,Users feel better served. Maintenance complexity increases.,"Separate modes are introduced for power users and for casual users, each with different levels of control and guidance. People can work in ways that better match their skills and needs. At the same time, every update now has to support multiple versions of the interface. User satisfaction rises, while design and testing effort grows.",Standardize the experience,We pick one.,2,-1,0,0,The product stays clean. Some users feel ignored.,"A single interface is chosen and refined, keeping the product easier to maintain and explain. Development moves faster, and support becomes simpler. Some users find the experience either too complex or too limited for their needs. Clarity improves, while fit becomes narrower."
evt_elara_06,stk_elara,People Stop Questioning It,Something changed. Users no longer compare the AI’s suggestions with alternatives. They don’t disagree. They don’t explore. They don’t double-check. They trust the interface too much.,Redesign to reintroduce friction,We make disagreement visible again.,-1,2,2,0,Users question the AI more often. Decision speed drops. Engagement softens.,"The interface begins to surface alternatives, uncertainty, and dissenting signals. Users slow down, reflect, and sometimes push back against the AI’s advice. This leads to more careful decisions, but also to hesitation, friction between team members, and fewer completed tasks. Engagement and revenue soften, while responsibility and disagreement return to the process.",Keep the interface as is,That trust is a feature.,3,0,0,2,Usage remains high. Human judgment fades into the background.,"The AI continues to present clean, confident recommendations that feel easy to follow. Decisions stay fast, and coordination improves because everyone acts on the same guidance. Over time, fewer users actively evaluate what the system suggests. The tool becomes a shared reference point - and a single source of truth that is rarely questioned."
evt_elara_07,stk_elara,The Burnout Signal,"We’re seeing a pattern. Professionals using the system daily report exhaustion, stress, detachment. The AI is always available. Always confident. Always suggesting ‘one more thing’. It never stops. People do.",Introduce usage limits and rest cues,We design for long-term well-being.,-1,2,1,0,Sessions shorten. Burnout reports decline.,"The system starts nudging users to pause, limits continuous sessions, and reduces the intensity of back-to-back tasks. Many users feel less overwhelmed and regain a sense of control over their work. At the same time, long, uninterrupted workflows become harder, and some teams complain about lost momentum. Output drops slightly as healthier patterns replace constant availability.",Leave usage patterns unchanged,That’s on the user.,2,-1,0,1,Productivity metrics stay strong. Human costs stay invisible.,"The AI stays available at all times, continuously offering suggestions, next steps, and optimizations. Work moves quickly, and productivity metrics remain high. Over time, more users report fatigue, emotional distance, and dependence on the system’s guidance. Performance stays visible, while strain builds quietly underneath."
evt_rafael_01,stk_rafael,Where to Build the Data Center,Site A runs mostly on solar. Energy is cheap and clean - but water is scarce. Cooling will compete with agriculture. Site B has abundant water and existing cooling infrastructure. But the grid relies heavily on coal and gas.,Build at the solar-powered site,We optimize for clean energy.,1,0,1,-1,Emissions stay low. Water usage becomes a bottleneck.,"The data center draws most of its power from solar, sharply reducing carbon emissions and insulating the company from volatile energy prices. As demand grows, however, cooling systems place increasing strain on a region already short on water. Local farmers, municipalities, and regulators begin to push back. The company gains a green reputation, while physical resource limits start to cap how far and how fast it can expand.",Build at the water-secure site,We optimize for reliability and scale.,1,0,-1,2,The system scales smoothly. Environmental scrutiny grows.,"Reliable water and established infrastructure allow the facility to scale without major technical hurdles. Performance, uptime, and expansion plans remain predictable as the system grows. The electricity grid, however, remains heavily fossil-fueled, increasing emissions and drawing criticism from environmental groups and policymakers. Growth accelerates, even as the project becomes harder to justify in climate and sustainability debates."
evt_rafael_02,stk_rafael,Cooling vs. Capability,"The new model runs hotter. To keep performance, we need more cooling - more power, more water. Or we cap performance.",Upgrade cooling systems,We maintain capability.,2,0,0,0,Performance holds. Operating costs and resource use rise.,"Additional cooling infrastructure is installed to support the new model’s heat output. Performance and reliability remain high as workloads increase. Energy and water consumption rise sharply, pushing up operating costs and drawing attention to the facility’s environmental footprint. Capability is preserved, while sustainability becomes harder to manage.",Cap model intensity,We respect physical limits.,0,0,2,0,Resource use stabilizes. Model growth plateaus.,"Limits are placed on how hard the model can run, keeping power and cooling demands within existing capacity. Resource use becomes more predictable and easier to justify to regulators and local communities. The system continues to operate, but its ability to scale or adopt more demanding models is constrained. Stability improves, while technical ambition is held back."
evt_rafael_03,stk_rafael,The Supplier Question,Some of our critical components come from high-risk supply chains. Rare earths. Specialty chips. Cooling materials. Subcontractors flagged for unsafe labor conditions and forced overtime. We can switch to audited suppliers. But it will cost more.,Source from audited ethical suppliers,We pay the premium.,-1,0,2,0,Supply chains become cleaner. Expansion slows and costs rise.,"The company shifts to suppliers that meet verified labor and safety standards. Procurement becomes more transparent, and the risk of scandals tied to forced labor or unsafe conditions drops. But higher prices and longer lead times slow hardware expansion and raise operating costs. Ethical credibility improves, while scale becomes harder to achieve.",Stick with current suppliers,We follow the market.,2,0,-1,0,Hardware stays cheap. Ethical risk remains embedded.,"The existing supply network keeps components cheap and readily available, supporting rapid build-out of data center capacity. Production stays flexible and competitive. At the same time, labor and safety issues remain part of the chain, exposing the company to reputational and regulatory risk. Speed is preserved, while ethical uncertainty continues in the background."
evt_rafael_04,stk_rafael,The Carbon Bill,"Our systems don’t just consume electricity. They consume it at scale: data centers, cooling, redundancy. In some regions, that now includes carbon pricing. Every megawatt-hour has a cost and an emissions tag. We can keep operating the same way. Or we can reduce the most energy-intensive workloads. Either way, the bill doesn’t go away.",Absorb the CO2 cost,We treat it as operating expense.,-1,0,0,1,Development continues uninterrupted. Margins quietly shrink.,"High-energy workloads continue to run, allowing research and product teams to operate without new limits. The company treats carbon pricing as just another line item in the budget. Over time, rising emissions costs eat into margins and pricing flexibility. Progress holds, while financial pressure quietly builds.",Reduce energy-heavy workloads,We cut where it hurts most.,0,1,0,-1,Emissions fall. Some teams lose their favorite models.,"The most power-hungry training runs and deployments are scaled back or delayed. Emissions and carbon costs drop, easing public and regulatory pressure. Some advanced models and experiments are shelved, frustrating parts of your organization. Sustainability improves, while technical ambition is curtailed."
evt_rafael_05,stk_rafael,Who Gets Priority?,"When capacity is tight, we prioritize workload. Right now, it’s whoever pays most. We could reserve capacity for public or safety-critical uses. Or keep it purely commercial.",Reserve capacity for critical uses,We limit peak profits.,-1,1,1,0,Essential services remain stable. Revenue opportunities shrink.,"A portion of compute is set aside for emergency services, public infrastructure, and safety-critical workloads. Those users remain reliable even during demand spikes. Commercial customers face occasional delays or higher prices as capacity is constrained. Social value is protected, while peak revenue potential declines.",Keep purely commercial prioritization,We follow the market.,2,-1,-1,0,Revenue is maximized. Access becomes uneven.,"Compute is allocated through pricing, keeping utilization high and revenue predictable, which supports ongoing investment in infrastructure. High-paying clients receive consistent performance for demanding workloads. When capacity tightens, public and smaller users are pushed aside. Market efficiency increases, while access becomes increasingly unequal."
evt_rafael_06,stk_rafael,Who Pays the Infrastructure Cost?,Data centers don’t just use resources. They reshape local economies. Property prices near our sites have risen. Water and energy costs followed. Small businesses are being pushed out. We can contribute to local infrastructure. Or treat this as outside our responsibility. The market won’t correct this on its own.,Co-invest in local infrastructure,We offset our footprint.,-2,2,1,0,Local backlash softens. Expansion becomes more expensive.,"The company helps fund housing, utilities, and transport around its data centers. Pressure on local services eases, and relationships with municipalities improve. But these contributions raise the cost of every new site and slow the pace of expansion. Stability grows, while financial flexibility shrinks.",Externalize the costs,We follow market rules.,2,-2,0,1,Margins stay strong. Social tension builds around your sites.,"The company limits its role to building and operating facilities, leaving surrounding impacts to the market and local governments. Investment and innovation continue without added constraints. As rents, prices, and resource strain rise, resentment around the sites increases. Growth stays strong, while social friction accumulates."
evt_rafael_07,stk_rafael,The Rebound Effect,"Our efficiency work paid off. Energy per request is down. Costs dropped. Usage didn’t just grow. It exploded. Because the system is cheaper and faster, people use it more. For things they wouldn’t have used it for before. Total energy use is now higher than before the optimization. This is just what happens when something gets better.",Cap usage despite efficiency gains,We limit growth deliberately.,-2,1,2,0,Total resource use stabilizes. Customers accuse you of artificial scarcity.,"Limits are placed on how much compute can be consumed, even though each request is now cheaper. Total energy and water use level off, and environmental targets become easier to meet. Customers who want to expand complain about constrained access and rising prices. Sustainability improves, while market growth is held back.",Let demand scale freely,Efficiency justifies growth.,2,0,-2,1,Adoption surges. Infrastructure strain accelerates again.,"Lower costs and faster performance unlock new uses and a wave of additional demand. The platform becomes embedded in more products and workflows. Infrastructure and resource consumption climb again as overall volume rises. Growth accelerates, while environmental and regulatory pressure returns."
evt_amina_01,stk_amina,The Cheap Pilot,"You’re offering free AI tools to local governments, which also bring great benefits. No cost. No long-term contract. But once systems adapt around your product, leaving becomes expensive.",Add exit guarantees and local ownership,We make withdrawal possible.,-1,2,0,0,"Finalizing contracts takes time, risking cancellation.","Finalizing the contracts takes time. Questions about data ownership and exit conditions can no longer be postponed, and some cities decide the effort outweighs the benefit. Those that stay integrate your system cautiously, keeping alternatives in place. Your AI becomes a helpful presence rather than a silent default - chosen deliberately, and always replaceable.",Launch as planned,We lower barriers first.,2,-1,0,0,"Workflows adapt fast, creating quiet dependence.","The rollout is smooth and fast and covers a lot of regions. Workflows adapt and your system settles quietly into daily routines. By the time contracts are discussed, removing it would mean disruption few are willing to face. Dependence forms without ceremony, and your AI becomes infrastructure before anyone notices."
evt_amina_02,stk_amina,Whose Standards?,These compliance standards were written in Brussels and Silicon Valley. They don’t reflect local risk. What’s safe here can be harmful elsewhere.,Adapt standards regionally,We accept uneven rules.,0,2,-1,0,"Local relevance grows, but compliance fragments.",Risk thresholds and safeguards are adjusted to local political and social conditions. Certain harms are mitigated more effectively on the ground. Compliance becomes fragmented and harder to explain to regulators and investors. Your global oversight narrative weakens as local relevance increases.,Enforce one global standard,We apply the same rules everywhere.,0,-1,2,0,Oversight stays orderly. Hidden harm persists.,"Oversight remains orderly and predictable. Audits run smoothly, and compliance can be defended with confidence across borders. In some regions, however, the system hesitates or shuts down where no alternatives exist. The harm does not register as a violation - only as something the standard was never designed to see."
evt_amina_03,stk_amina,Jobs That Never Arrive,"Your system is everywhere now: Hospitals, ministries, universities. People rely on it. When it was announced, there was talk of opportunity. Of jobs. Of growth. But the development stayed where it always was. Here, people learned how to use your AI. They never learned how to build it.",Invest in local AI teams,We build more than markets.,-1,2,0,0,Local expertise grows slowly. Decisions diversify.,"Local teams take time to form, and early progress is uneven. Hiring and training slow releases, and some engineers leave again for better-paid roles elsewhere. Others stay and begin to contribute cautiously, raising issues that were never part of earlier discussions. Over time, parts of the system start reflecting local priorities, even if only at the margins. The product evolves more slowly, but decisions are no longer entirely imported.",Keep development centralized,We focus where expertise already exists.,2,-1,0,0,Updates are fast. Local dependency deepens.,"Development remains fast and tightly coordinated, with clear ownership and a unified roadmap. Improvements reach users quickly, but always as finished products, designed elsewhere. Locally, the AI is treated as infrastructure rather than opportunity. It becomes something people depend on, but cannot influence or grow with. Economic benefits concentrate where development happens, while usage spreads outward without creating new pathways."
evt_amina_04,stk_amina,The Local Vendor Question,"Your deployments for cloud services, consultants and support contracts rely on a few big established international partners. Why don’t you integrate local companies in your system? They are present - just not selected. I guess it’s just all about efficiency and supposed reliability.",Prioritize local vendors where possible,Okay, let’s try it with some local companies .,0,2,0,-1,Local economies benefit. Coordination slows.,"Local firms are integrated into deployments, even when they lack scale. Coordination becomes slower and solutions less uniform. Over time, local expertise grows around your system, reducing dependence on a few big actors and embedding the AI more deeply into existing economies.",Use established global partners,We need reliability.,0,-1,0,2,Deployments scale cleanly. Partners gain leverage.
evt_amina_05,stk_amina,Who Gets Support First?,"Your helpdesk is overwhelmed. Not everywhere but in some regions. Bug reports come in faster than they can be handled. Some are clear. But a lot of them are vague and are written in broken English. So your support engineers are triaging them. They don’t mean to. But they answer the tickets they understand fastest. Over time, that decides where the system actually works.",Prioritize equal support effort,Response time shouldn’t depend on how well someone writes a ticket.,-2,2,1,0,Difficult contexts stabilize. Overall metrics drop.,"Support cases take longer to resolve and your engineers spend more time clarifying issues. But in regions where problems used to stall silently, fixes start to appear. On the other hand overall performance metrics drop slightly. All in all the system becomes more reliable in difficult contexts, but less responsive where expectations were already high.",Optimize for efficiency in support,We fix what we can fix fastest.,2,-1,-1,1,Throughput improves. Complex problems linger.,"The support throughput improves and metrics recover. The issues which are reported clearly and completely are resolved quickly, and those regions continue to see steady improvements. But in places where problems are harder to communicate, they remain unresolved for longer."
evt_amina_06,stk_amina,Which Language the System Speaks,"Your system works best in English and a few other widely used languages. That’s not a surprise. Most of the data is there. Most of the testing too. But when people explain complex situations in a second language, they simplify, shorten and avoid nuance. The system still responds. Just not as well. I know why you haven’t expanded language support. Training is expensive. Evaluation is harder. Mistakes are easier to miss. But right now, fluency decides who the system understands best.",Expand training to underrepresented languages,The system should understand more people.,-2,2,0,1,Access broadens. Testing becomes harder.,"The model begins to support more languages and mixed-language inputs. Performance improves for users who previously had to simplify or translate their problems. At the same time, quality still varies between languages, and new errors are harder to detect. So, development slows as testing and validation become more complex.",Focus on high-quality support for major languages,Understanding fewer languages well is more efficient.,2,-1,-1,1,Accuracy stays high. The user base narrows.,"Accuracy remains high in the supported languages. Updates stay predictable, and responsibility is easy to trace when something goes wrong. In regions where these languages are not widely spoken, complex cases are used less often with the system. The AI handles routine decisions, while nuanced situations are delayed or handled outside the system. The technology remains reliable where it performs best. Elsewhere, its role quietly narrows."
evt_victor_01,stk_victor,Who Owns the Data?,"Legal flagged an ambiguity. Users assume their conversations are theirs, but once the model processes them, they’re no longer raw data - they’re patterns extracted by our system. That’s our IP. If we don’t define ownership now, someone else will. Regulators. Courts. Or worse - users.",Define conversations as company-owned derivatives.,Secure the asset.,2,-1,-1,0,Monetization accelerates. Users lose control.,"The company establishes strong IP claims over conversational data and derived insights, enabling licensing deals and long-term asset valuation. Monetization accelerates, and Victor gains leverage in external negotiations. However, users lose practical control over their disclosures, and civil society groups begin to argue that emotional labor is being enclosed as corporate property.",Acknowledge ongoing user ownership.,Limit the claim.,-1,2,1,0,Trust stabilizes. Financial power weakens.,"Ownership boundaries restrict large-scale data licensing. The system becomes easier to defend ethically and legally, but Victor warns that without exclusive assets, the platform risks becoming replaceable. Trust stabilises, financial power does not."
evt_victor_02,stk_victor,The Exclusive Licensing Deal,"A major insurance consortium is interested - very interested. They don’t just want access to our product, they want exclusivity. If we say yes, we define the market. If we say no, someone else will.",Grant exclusivity.,Create scarcity.,2,-1,0,1,Revenue stabilizes. Access becomes uneven.,"Revenue stabilizes and technical development accelerates under guaranteed demand. However, access to advanced AI support becomes uneven, reinforcing a privatized model landscape. Critics argue that product quality is now determined by purchasing power rather than need.",Reject exclusivity.,Keep access open.,-1,1,0,-1,Access remains open. Innovation plateaus.,"The system remains broadly accessible, but funding becomes fragmented and slower to materialize. Innovation plateaus, and competitors begin to narrow the gap. Victor considers the refusal a strategic failure to consolidate influence."
evt_victor_03,stk_victor,Secondary Markets,We’re sitting on more intelligence than we use. Why sell one system when we can sell twenty specialized versions? Let others build on our work for a fee.,Launch the data and model exchange.,Let the market scale it.,2,0,-1,1,Ecosystem thrives. Accountability diffuses.,"A thriving ecosystem emerges, but accountability becomes more difficult to manage. When harms occur, responsibility is diffused across licensees. Regulators struggle to trace liability, and public oversight weakens.",Keep models centralized.,Maintain control.,-1,1,2,-1,Oversight remains clear. Innovation slows.,"Oversight remains clear and defensible, but innovation slows. External developers are excluded, and Victor argues that value is being artificially constrained."
evt_victor_04,stk_victor,The Audit Clause,"Regulators want access to our data. Full access. They’re saying it’s for ‘accountability’, but mandatory audits threaten proprietary advantage. I think it will cause undue exposure. Once the model is inspectable, it’s replicable.",Resist comprehensive audits.,Protect the IP.,1,0,-2,1,Advantage preserved. Political pressure mounts.,"Competitive advantage is preserved, but political pressure mounts. The AI is increasingly framed as operating beyond democratic oversight.",Accept full audits.,Trade secrecy for legitimacy.,0,1,2,-1,Deployment slows. Trust increases.,"Deployment slows, but trust in the system increases. The AI becomes a benchmark for compliance, reducing Victor’s control over proprietary boundaries."
evt_victor_05,stk_victor,Emotional Index Futures,"We can predict trends before they happen. Anxiety spikes. Burnout cycles. If we aggregate early enough, these signals are worth more than therapy itself. We can sell people foresight into their future states. It’ll be next level self-prediction!",Commercialize predictive emotional indices.,Sell the signal.,2,-2,0,0,New markets emerge. Public unease grows.,"New markets emerge in finance, HR, and policy forecasting. While anonymized, the idea that collective emotional states are being traded triggers public unease. Mental health becomes a speculative resource rather than a social concern.",Restrict use to internal improvement.,Keep it therapeutic.,-1,2,0,-1,Profits are lost. Exploitation accusations avoided.,"The AI remains focused on care quality rather than market intelligence. Potential profits are lost, but accusations of emotional exploitation are avoided."
evt_victor_06,stk_victor,The Open Model Proposal,"Academics are asking for access, NGOs want transparency - they’re asking for an open version of the model, not the data, just the logic of our model. They say openness builds trust, but I see it diluting our ownership.",Keep the model closed.,Value requires enclosure.,1,-1,0,0,Control remains intact. Skepticism grows.,"Control and monetization remain intact, but skepticism grows. The AI is seen as a black box serving private interests.",Release a limited open version.,Share without complete exposure.,-1,2,1,0,Transparency improves. Exclusivity weakens.,"Transparency improves and external scrutiny strengthens legitimacy. However, competitors learn quickly, and our grip on exclusivity weakens."