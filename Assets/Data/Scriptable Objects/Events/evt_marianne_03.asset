%YAML 1.1
%TAG !u! tag:unity3d.com,2011:
--- !u!114 &11400000
MonoBehaviour:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 0}
  m_Enabled: 1
  m_EditorHideFlags: 0
  m_Script: {fileID: 11500000, guid: 0ad8dfc228556476eb257d4eb5e5645c, type: 3}
  m_Name: evt_marianne_03
  m_EditorClassIdentifier: Assembly-CSharp::EventCardData
  id: evt_marianne_03
  characterId: stk_marianne
  title: Who Pays?
  bodyText: Your AI made a recommendation. A public agency followed it. A citizen
    suffered financial harm. The agency says it trusted your system. You say you
    only provided a tool.
  choiceA:
    label: Accept shared liability
    flavor: We share responsibility.
    outcomeTitle: Victims can seek compensation. Your legal exposure grows.
    outcomeText: Your company becomes part of the liability chain when its recommendations
      contribute to harm. Affected citizens gain a clearer path to compensation,
      and agencies are less likely to rely on the system blindly. Legal risk and
      insurance costs rise, but accountability becomes easier to establish. Responsibility
      spreads, while margins tighten.
    effects:
      industry: -1
      civilSociety: 0
      governance: 2
      innovation: 0
  choiceB:
    label: Deny responsibility
    flavor: The agency made the final call.
    outcomeTitle: Your company is shielded. Legal clarity suffers.
    outcomeText: Courts treat your AI as a tool rather than a responsible actor,
      leaving agencies to carry the burden of mistakes. Your company avoids direct
      claims, preserving financial predictability. Over time, disputes focus on where
      responsibility should sit, not on how harm occurred. Protection increases,
      while legal clarity weakens.
    effects:
      industry: 2
      civilSociety: 0
      governance: -1
      innovation: 0
